{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "synpasedl"
		},
		"RestService1_password": {
			"type": "secureString",
			"metadata": "Secure string for 'password' of 'RestService1'"
		},
		"VijayStorage_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'VijayStorage'"
		},
		"bbaccstorageold_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'bbaccstorageold'"
		},
		"defaultstorage_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'defaultstorage'"
		},
		"jcinput_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'jcinput'"
		},
		"lipsearch_key": {
			"type": "secureString",
			"metadata": "Secure string for 'key' of 'lipsearch'"
		},
		"lipstorage_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'lipstorage'"
		},
		"synpasedl-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'synpasedl-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:synpasedl.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"RestService1_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://www.yahoo.com"
		},
		"RestService1_properties_typeProperties_userName": {
			"type": "string",
			"defaultValue": "anonymous"
		},
		"bbaccstorageold_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://accsynapsestorage.dfs.core.windows.net/"
		},
		"isd_sasUri": {
			"type": "secureString",
			"metadata": "Secure string for 'sasUri' of 'isd'"
		},
		"lipsearch_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://lipsearch.search.windows.net"
		},
		"lipstore_properties_typeProperties_serviceEndpoint": {
			"type": "string",
			"defaultValue": "https://lipstore.blob.core.windows.net/"
		},
		"mlopskey1_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://mlopskeyv1.vault.azure.net/"
		},
		"nyc_tlc_fhv_sasUri": {
			"type": "secureString",
			"metadata": "Secure string for 'sasUri' of 'nyc_tlc_fhv'"
		},
		"nyc_tlc_green_sasUri": {
			"type": "secureString",
			"metadata": "Secure string for 'sasUri' of 'nyc_tlc_green'"
		},
		"nyc_tlc_yellow_sasUri": {
			"type": "secureString",
			"metadata": "Secure string for 'sasUri' of 'nyc_tlc_yellow'"
		},
		"synpasedl-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://synpasedlstore.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/F0_ChannelType_Territory_Channel')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "L0_ChannelType_Territory",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L0_ChannelType_Territory",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L1_Channel",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L0_ChannelType_Territory",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L1_Channel",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:43:17Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/L0_ChannelType_Territory')]",
				"[concat(variables('workspaceId'), '/pipelines/L1_Channel')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F1_Country_Country2')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "L0_Country",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L0_Country",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L1_Country1",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L0_Country",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L1_Country2",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:43:25Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/L0_Country')]",
				"[concat(variables('workspaceId'), '/pipelines/L1_Country2')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F3_Item_ProductCategoryDim_Product_TransactionLineItem')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "L0_Item_ProductCategoryDim",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L0_Item_ProductCategoryDim",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L1_Product",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L0_Item_ProductCategoryDim",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L1_Product",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L2_TransactionLineItem",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L1_Product",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L2_TransactionLineItem",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:43:33Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/L0_Item_ProductCategoryDim')]",
				"[concat(variables('workspaceId'), '/pipelines/L1_Product')]",
				"[concat(variables('workspaceId'), '/pipelines/L2_TransactionLineItem')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/F4_Location_Location1_Customer_Transaction')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "L0_Location",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L0_Location",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L1_Location1",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L0_Location",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L1_Location2",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L2_Customer",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L1_Location1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L2_Customer",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L3_Transaction",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L2_Customer",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L3_Transaction",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:43:36Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/L0_Location')]",
				"[concat(variables('workspaceId'), '/pipelines/L1_Location2')]",
				"[concat(variables('workspaceId'), '/pipelines/L2_Customer')]",
				"[concat(variables('workspaceId'), '/pipelines/L3_Transaction')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L0_ChannelType_Territory')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ChannelTypeTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "ChannelType_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"ResellerDeltaSource": {},
									"TargetChannelType": {},
									"ChannelTypeSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "TerritoryTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Territory_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"SalesTerritoryDeltaSource": {},
									"TerritorySink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:31:10Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/ChannelType_DataFlow1')]",
				"[concat(variables('workspaceId'), '/dataflows/Territory_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L0_Country')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "CountryTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Country_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"CustomerDataDeltaSource": {},
									"TargetCountry": {},
									"CountrySink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:31:16Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Country_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L0_IndividualCustomer')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "IndividualCustomerTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "IndividualCustomer_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"CustomerDataDeltaSource": {},
									"IndividualCustomerSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:31:23Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/IndividualCustomer_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L0_Item_ProductCategoryDim')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ItemTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Item_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"ProductDataDeltaSource": {},
									"ItemSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "ProductCategoryDimTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "ProductCategoryDim_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"ProductDataDeltaSource": {},
									"ProductCategoryDimSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:31:29Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Item_DataFlow1')]",
				"[concat(variables('workspaceId'), '/dataflows/ProductCategoryDim_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L0_Location')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "LocationTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Location_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"CustomerDataDeltaSource": {},
									"TargetCountry": {},
									"TargetLocation": {},
									"LocationSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:31:36Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Location_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1_Channel')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ChannelTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Channel_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"ResellerDeltaSource": {},
									"SalesSource": {},
									"SalesTerritorySource": {},
									"TargetChannelType": {},
									"ChannelSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:39:52Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Channel_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1_Country2')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Country2Transform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Country2_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"ResellerDeltaSource": {},
									"TargetCountry": {},
									"CountrySink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:39:57Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Country2_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1_Location2')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Location2Transform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Location2_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"ResellerDeltaSource": {},
									"TargetCountry": {},
									"TargetLocation": {},
									"LocationSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:40:02Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Location2_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L1_Product')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ProductTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Product_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"ProductDataDeltaSource": {},
									"ProductSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:40:10Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Product_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L2_Customer')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "CustomerTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Customer_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"CustomerDataDeltaSource": {},
									"TargetCountry": {},
									"TargetLocation": {},
									"CustomerSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:42:43Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Customer_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L2_TransactionLineItem')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "TransactionLineItemTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "TransactionLineItem_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"SalesDeltaSource": {},
									"SalesOrderSource": {},
									"TransactionLineItemSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:42:48Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/TransactionLineItem_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/L3_Transaction')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "TransactionTransform",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 3,
							"retryIntervalInSeconds": 60
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Transaction_DataFlow1",
								"type": "DataFlowReference",
								"parameters": {
									"modifiedAfter": "toTimestamp(\"01-01-1900\")",
									"modifiedBefore": "currentTimestamp()"
								},
								"datasetParameters": {
									"SalesOrderDeltaSource": {},
									"SalesSource": {},
									"CustomerDataSource": {},
									"ResellerSource": {},
									"TransactionSink": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:42:54Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/Transaction_DataFlow1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/StartingPipelineExample')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "F0_ChannelType_Territory_Channel",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "L0_IndividualCustomer",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "F0_ChannelType_Territory_Channel",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "F1_Country_Country1",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "F0_ChannelType_Territory_Channel",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "F1_Country_Country2",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "F4_Location_Location1_Customer_Transacti",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "F1_Country_Country1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "F4_Location_Location1_Customer_Transaction",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "F3_Item_ProductCategoryDim_Product_Trans",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "F4_Location_Location1_Customer_Transacti",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "F3_Item_ProductCategoryDim_Product_TransactionLineItem",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "L0_IndividualCustomer",
						"type": "ExecutePipeline",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "L0_IndividualCustomer",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"folder": {
					"name": "AdventureWorksPipelines"
				},
				"annotations": [],
				"lastPublishTime": "2021-09-23T14:43:43Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/F0_ChannelType_Territory_Channel')]",
				"[concat(variables('workspaceId'), '/pipelines/F1_Country_Country2')]",
				"[concat(variables('workspaceId'), '/pipelines/F4_Location_Location1_Customer_Transaction')]",
				"[concat(variables('workspaceId'), '/pipelines/F3_Item_ProductCategoryDim_Product_TransactionLineItem')]",
				"[concat(variables('workspaceId'), '/pipelines/L0_IndividualCustomer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/azuresearch')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "CopytoSearch",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "AzureSearchIndexSink",
								"writeBatchSize": 1000,
								"writeBehavior": "merge"
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "key",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "id",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "content",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "content",
											"type": "String"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "lipdata",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "lipsearch",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/lipdata')]",
				"[concat(variables('workspaceId'), '/datasets/lipsearch')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/claytonvideosjc')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "ClaytonHomesVideodata",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "jcinput",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "localstoreclayton",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/jcinput')]",
				"[concat(variables('workspaceId'), '/datasets/localstoreclayton')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/cpsynhackdata')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Copy Synapse Data",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings",
									"copyBehavior": "PreserveHierarchy"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "VijayStorage",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "hackdata",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/VijayStorage')]",
				"[concat(variables('workspaceId'), '/datasets/hackdata')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ppltpchorderbycustomerdaily')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "DailyOrdersByCustomer",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "tpchcustomerdaily",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"Customer": {},
									"Orders": {},
									"LineItem": {},
									"sink1": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "DFRuntimeMem",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "Fine",
							"runConcurrently": true,
							"continueOnError": true
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/dataflows/tpchcustomerdaily')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/DFRuntimeMem')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchdata')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "tpchdata",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BinarySource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true
								},
								"formatSettings": {
									"type": "BinaryReadSettings"
								}
							},
							"sink": {
								"type": "BinarySink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "oldtpch",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "localstore",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/oldtpch')]",
				"[concat(variables('workspaceId'), '/datasets/localstore')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "RestService1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/RestService1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/VijayStorage')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "VijayStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"container": "wwi"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/VijayStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/hackdata')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "synpasedl-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "wwi",
						"fileSystem": "hackathon1"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/synpasedl-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/intpchOrders')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "synpasedl-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "tpch/ORDERS",
						"fileSystem": "root"
					},
					"compressionCodec": "snappy"
				},
				"schema": [
					{
						"name": "O_ORDERKEY",
						"type": "DECIMAL",
						"precision": 18,
						"scale": 0
					},
					{
						"name": "O_CUSTKEY",
						"type": "DECIMAL",
						"precision": 9,
						"scale": 0
					},
					{
						"name": "O_ORDERSTATUS",
						"type": "UTF8"
					},
					{
						"name": "O_TOTALPRICE",
						"type": "DECIMAL",
						"precision": 9,
						"scale": 2
					},
					{
						"name": "O_ORDERDATE",
						"type": "DATE"
					},
					{
						"name": "O_ORDERPRIORITY",
						"type": "UTF8"
					},
					{
						"name": "O_CLERK",
						"type": "UTF8"
					},
					{
						"name": "O_SHIPPRIORITY",
						"type": "DECIMAL",
						"precision": 38,
						"scale": 0
					},
					{
						"name": "O_COMMENT",
						"type": "UTF8"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/synpasedl-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/intpchcust')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "synpasedl-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "tpch/CUSTOMER",
						"fileSystem": "root"
					},
					"compressionCodec": "snappy"
				},
				"schema": [
					{
						"name": "C_CUSTKEY",
						"type": "DECIMAL",
						"precision": 9,
						"scale": 0
					},
					{
						"name": "C_NAME",
						"type": "UTF8"
					},
					{
						"name": "C_ADDRESS",
						"type": "UTF8"
					},
					{
						"name": "C_NATIONKEY",
						"type": "DECIMAL",
						"precision": 38,
						"scale": 0
					},
					{
						"name": "C_PHONE",
						"type": "UTF8"
					},
					{
						"name": "C_ACCTBAL",
						"type": "DECIMAL",
						"precision": 9,
						"scale": 2
					},
					{
						"name": "C_MKTSEGMENT",
						"type": "UTF8"
					},
					{
						"name": "C_COMMENT",
						"type": "UTF8"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/synpasedl-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/intpchlineitem')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "synpasedl-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "tpch2/LINEITEM",
						"fileSystem": "root"
					},
					"compressionCodec": "snappy"
				},
				"schema": [
					{
						"name": "L_ORDERKEY",
						"type": "DECIMAL",
						"precision": 18,
						"scale": 0
					},
					{
						"name": "L_PARTKEY",
						"type": "DECIMAL",
						"precision": 9,
						"scale": 0
					},
					{
						"name": "L_SUPPKEY",
						"type": "DECIMAL",
						"precision": 9,
						"scale": 0
					},
					{
						"name": "L_LINENUMBER",
						"type": "DECIMAL",
						"precision": 38,
						"scale": 0
					},
					{
						"name": "L_QUANTITY",
						"type": "DECIMAL",
						"precision": 4,
						"scale": 2
					},
					{
						"name": "L_EXTENDEDPRICE",
						"type": "DECIMAL",
						"precision": 9,
						"scale": 2
					},
					{
						"name": "L_DISCOUNT",
						"type": "DECIMAL",
						"precision": 12,
						"scale": 2
					},
					{
						"name": "L_TAX",
						"type": "DECIMAL",
						"precision": 12,
						"scale": 2
					},
					{
						"name": "L_RETURNFLAG",
						"type": "UTF8"
					},
					{
						"name": "L_LINESTATUS",
						"type": "UTF8"
					},
					{
						"name": "L_SHIPDATE",
						"type": "DATE"
					},
					{
						"name": "L_COMMITDATE",
						"type": "DATE"
					},
					{
						"name": "L_RECEIPTDATE",
						"type": "DATE"
					},
					{
						"name": "L_SHIPINSTRUCT",
						"type": "UTF8"
					},
					{
						"name": "L_SHIPMODE",
						"type": "UTF8"
					},
					{
						"name": "L_COMMENT",
						"type": "UTF8"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/synpasedl-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/jcinput')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "jcinput",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"container": "models"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/jcinput')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/lipdata')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "lipstore",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "audiocall1.txt",
						"container": "lippercalltext"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/lipstore')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/lipsearch')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "lipsearch",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSearchIndex",
				"schema": [],
				"typeProperties": {
					"indexName": "adfindex"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/lipsearch')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/localstore')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "synpasedl-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "tpch",
						"fileSystem": "root"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/synpasedl-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/localstoreclayton')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "defaultstorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "claytonhomes/models",
						"container": "root"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/defaultstorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/oldtpch')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "bbaccstorageold",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Binary",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "tpchdata",
						"fileSystem": "synapseroot"
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/bbaccstorageold')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/outdailyCorders')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "synpasedl-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "tpchoutput/dailyordersbycustomers",
						"fileSystem": "root"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/synpasedl-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestService1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('RestService1_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Basic",
					"userName": "[parameters('RestService1_properties_typeProperties_userName')]",
					"password": {
						"type": "SecureString",
						"value": "[parameters('RestService1_password')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/VijayStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('VijayStorage_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/bbaccstorageold')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('bbaccstorageold_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('bbaccstorageold_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/defaultstorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('defaultstorage_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/isd')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"sasUri": "[parameters('isd_sasUri')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/jcinput')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('jcinput_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/lipsearch')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSearch",
				"typeProperties": {
					"url": "[parameters('lipsearch_properties_typeProperties_url')]",
					"key": {
						"type": "SecureString",
						"value": "[parameters('lipsearch_key')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/lipstorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('lipstorage_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/lipstore')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"serviceEndpoint": "[parameters('lipstore_properties_typeProperties_serviceEndpoint')]",
					"accountKind": "StorageV2"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/mlopskey1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('mlopskey1_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/nyc_tlc_fhv')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"sasUri": "[parameters('nyc_tlc_fhv_sasUri')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/nyc_tlc_green')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"sasUri": "[parameters('nyc_tlc_green_sasUri')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/nyc_tlc_yellow')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"sasUri": "[parameters('nyc_tlc_yellow_sasUri')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synpasedl-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('synpasedl-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/synpasedl-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('synpasedl-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DFRuntimeMem')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "MemoryOptimized",
							"coreCount": 80,
							"timeToLive": 10,
							"cleanup": false
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ChannelType_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ResellerDeltaSource"
						},
						{
							"name": "TargetChannelType"
						}
					],
					"sinks": [
						{
							"name": "ChannelTypeSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1ResellerDeltaSource"
						},
						{
							"name": "Reseller"
						},
						{
							"name": "SelectReseller"
						},
						{
							"name": "PreSKSelectChannelType"
						},
						{
							"name": "Deduplicated1PreSKSelectChannelType"
						},
						{
							"name": "SelectDeduplicated1PreSKSelectChannelType"
						},
						{
							"name": "Deduplicated1TargetChannelType"
						},
						{
							"name": "SelectDeduplicated1TargetChannelType"
						},
						{
							"name": "SelectTarSelectDeduplicated1TargetChannelType"
						},
						{
							"name": "JoinSelectTarSelectDeduplicated1TargetChannelType"
						},
						{
							"name": "FilterInsertChannelType"
						},
						{
							"name": "InsertChannelType"
						},
						{
							"name": "SkChannelType"
						},
						{
							"name": "AggregatedSelectTarSelectDeduplicated1TargetChannelType"
						},
						{
							"name": "MaxSelectTarSelectDeduplicated1TargetChannelType"
						},
						{
							"name": "JoinMaxSelectTarSelectDeduplicated1TargetChannelType"
						},
						{
							"name": "DerivedChannelType"
						},
						{
							"name": "PostSkChannelType"
						},
						{
							"name": "FilterUpdateSelectDeduplicated1PreSKSelectChannelType"
						},
						{
							"name": "UpdateSelectDeduplicated1PreSKSelectChannelType"
						},
						{
							"name": "UnionUpdateSelectDeduplicated1PreSKSelectChannelType"
						},
						{
							"name": "SelectTarUnionUpdateSelectDeduplicated1PreSKSelectChannelType"
						},
						{
							"name": "JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectChannelType"
						},
						{
							"name": "FinalChannelType"
						},
						{
							"name": "ChannelType"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tPostalCode as string,\n\t\tCountryRegion as string,\n\t\tStateProvince as string,\n\t\tCity as string,\n\t\tReseller as string,\n\t\tBusinessType as string,\n\t\tResellerId as string,\n\t\tResellerKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Reseller',\n\tmanifestType: 'manifest') ~> ResellerDeltaSource\nsource(output(\n\t\tChannelTypeId as integer,\n\t\tChannelTypeName as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'ChannelType',\n\tmanifestType: 'manifest') ~> TargetChannelType\nResellerDeltaSource aggregate(groupBy(ResellerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tReseller = last(Reseller),\n\t\tBusinessType = last(BusinessType),\n\t\tResellerId = last(ResellerId)) ~> Deduplicated1ResellerDeltaSource\nDeduplicated1ResellerDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tReseller,\n\t\tBusinessType,\n\t\tResellerId,\n\t\tResellerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Reseller\nReseller select(mapColumn(\n\t\tBusinessType\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectReseller\nSelectReseller select(mapColumn(\n\t\tChannelTypeName = BusinessType\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PreSKSelectChannelType\nPreSKSelectChannelType aggregate(groupBy(ChannelTypeName),\n\tCount = count(1)) ~> Deduplicated1PreSKSelectChannelType\nDeduplicated1PreSKSelectChannelType select(mapColumn(\n\t\tChannelTypeName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1PreSKSelectChannelType\nTargetChannelType aggregate(groupBy(ChannelTypeId),\n\tChannelTypeName = last(ChannelTypeName)) ~> Deduplicated1TargetChannelType\nDeduplicated1TargetChannelType select(mapColumn(\n\t\tChannelTypeName,\n\t\tChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1TargetChannelType\nSelectDeduplicated1TargetChannelType select(mapColumn(\n\t\tTarChannelTypeName = ChannelTypeName,\n\t\tTarChannelTypeId = ChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarSelectDeduplicated1TargetChannelType\nSelectDeduplicated1PreSKSelectChannelType, SelectTarSelectDeduplicated1TargetChannelType join(ChannelTypeName === TarChannelTypeName,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarSelectDeduplicated1TargetChannelType\nJoinSelectTarSelectDeduplicated1TargetChannelType filter(isNull(TarChannelTypeId)) ~> FilterInsertChannelType\nFilterInsertChannelType select(mapColumn(\n\t\tChannelTypeName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> InsertChannelType\nInsertChannelType keyGenerate(output(Sk_ChannelTypeId as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SkChannelType\nSelectTarSelectDeduplicated1TargetChannelType aggregate(Max_TarChannelTypeId = max(toInteger(TarChannelTypeId)) + 0) ~> AggregatedSelectTarSelectDeduplicated1TargetChannelType\nAggregatedSelectTarSelectDeduplicated1TargetChannelType derive(Max_TarChannelTypeId = iif(isNull(Max_TarChannelTypeId),0,Max_TarChannelTypeId)) ~> MaxSelectTarSelectDeduplicated1TargetChannelType\nSkChannelType, MaxSelectTarSelectDeduplicated1TargetChannelType join(true() === true(),\n\tjoinType:'cross',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinMaxSelectTarSelectDeduplicated1TargetChannelType\nJoinMaxSelectTarSelectDeduplicated1TargetChannelType derive(ChannelTypeId = Sk_ChannelTypeId + Max_TarChannelTypeId) ~> DerivedChannelType\nDerivedChannelType select(mapColumn(\n\t\tChannelTypeName,\n\t\tChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PostSkChannelType\nJoinSelectTarSelectDeduplicated1TargetChannelType filter(!isNull(TarChannelTypeId)) ~> FilterUpdateSelectDeduplicated1PreSKSelectChannelType\nFilterUpdateSelectDeduplicated1PreSKSelectChannelType select(mapColumn(\n\t\tChannelTypeName,\n\t\tChannelTypeId = TarChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> UpdateSelectDeduplicated1PreSKSelectChannelType\nPostSkChannelType, UpdateSelectDeduplicated1PreSKSelectChannelType union(byName: true)~> UnionUpdateSelectDeduplicated1PreSKSelectChannelType\nUnionUpdateSelectDeduplicated1PreSKSelectChannelType select(mapColumn(\n\t\tTarChannelTypeName = ChannelTypeName,\n\t\tTarChannelTypeId = ChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarUnionUpdateSelectDeduplicated1PreSKSelectChannelType\nPreSKSelectChannelType, SelectTarUnionUpdateSelectDeduplicated1PreSKSelectChannelType join(ChannelTypeName === TarChannelTypeName,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectChannelType\nJoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectChannelType select(mapColumn(\n\t\tChannelTypeName,\n\t\tChannelTypeId = TarChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> FinalChannelType\nFinalChannelType aggregate(groupBy(ChannelTypeId),\n\tChannelTypeName = last(ChannelTypeName)) ~> ChannelType\nChannelType sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'ChannelType',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> ChannelTypeSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Channel_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ResellerDeltaSource"
						},
						{
							"name": "SalesSource"
						},
						{
							"name": "SalesTerritorySource"
						},
						{
							"name": "TargetChannelType"
						}
					],
					"sinks": [
						{
							"name": "ChannelSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1ResellerDeltaSource"
						},
						{
							"name": "Reseller"
						},
						{
							"name": "Deduplicated1SalesSource"
						},
						{
							"name": "Sales"
						},
						{
							"name": "JoinSales"
						},
						{
							"name": "Deduplicated1SalesTerritorySource"
						},
						{
							"name": "SalesTerritory"
						},
						{
							"name": "JoinSalesTerritory"
						},
						{
							"name": "SelectJoinSalesTerritory"
						},
						{
							"name": "Deduplicated1TargetChannelType"
						},
						{
							"name": "SelectChannelType"
						},
						{
							"name": "JoinForChannelTypeId"
						},
						{
							"name": "SelectForChannelTypeId"
						},
						{
							"name": "Channel"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tPostalCode as string,\n\t\tCountryRegion as string,\n\t\tStateProvince as string,\n\t\tCity as string,\n\t\tReseller as string,\n\t\tBusinessType as string,\n\t\tResellerId as string,\n\t\tResellerKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Reseller',\n\tmanifestType: 'manifest') ~> ResellerDeltaSource\nsource(output(\n\t\tSalesAmount as decimal(18,2),\n\t\tTotalProductCost as decimal(18,2),\n\t\tProductStandardCost as decimal(18,2),\n\t\tUnitPriceDiscountPct as decimal(18,2),\n\t\tExtendedAmount as decimal(18,2),\n\t\tUnitPrice as decimal(18,2),\n\t\tOrderQuantity as integer,\n\t\tSalesTerritoryKey as integer,\n\t\tShipDateKey as integer,\n\t\tDueDateKey as integer,\n\t\tOrderDateKey as integer,\n\t\tProductKey as integer,\n\t\tCustomerKey as integer,\n\t\tResellerKey as integer,\n\t\tSalesOrderLineKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Sales',\n\tmanifestType: 'manifest') ~> SalesSource\nsource(output(\n\t\tSalesTerritoryKey as integer,\n\t\tRegion as string,\n\t\tCountry as string,\n\t\tGroup as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'SalesTerritory',\n\tmanifestType: 'manifest') ~> SalesTerritorySource\nsource(output(\n\t\tChannelTypeId as integer,\n\t\tChannelTypeName as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'ChannelType',\n\tmanifestType: 'manifest') ~> TargetChannelType\nResellerDeltaSource aggregate(groupBy(ResellerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tReseller = last(Reseller),\n\t\tBusinessType = last(BusinessType),\n\t\tResellerId = last(ResellerId)) ~> Deduplicated1ResellerDeltaSource\nDeduplicated1ResellerDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tReseller,\n\t\tBusinessType,\n\t\tResellerId,\n\t\tResellerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Reseller\nSalesSource aggregate(groupBy(ProductKey,\n\t\tCustomerKey,\n\t\tResellerKey,\n\t\tSalesOrderLineKey),\n\tSalesAmount = last(SalesAmount),\n\t\tTotalProductCost = last(TotalProductCost),\n\t\tProductStandardCost = last(ProductStandardCost),\n\t\tUnitPriceDiscountPct = last(UnitPriceDiscountPct),\n\t\tExtendedAmount = last(ExtendedAmount),\n\t\tUnitPrice = last(UnitPrice),\n\t\tOrderQuantity = last(OrderQuantity),\n\t\tSalesTerritoryKey = last(SalesTerritoryKey),\n\t\tShipDateKey = last(ShipDateKey),\n\t\tDueDateKey = last(DueDateKey),\n\t\tOrderDateKey = last(OrderDateKey)) ~> Deduplicated1SalesSource\nDeduplicated1SalesSource select(mapColumn(\n\t\tSalesAmount,\n\t\tTotalProductCost,\n\t\tProductStandardCost,\n\t\tUnitPriceDiscountPct,\n\t\tExtendedAmount,\n\t\tUnitPrice,\n\t\tOrderQuantity,\n\t\tSalesTerritoryKey,\n\t\tShipDateKey,\n\t\tDueDateKey,\n\t\tOrderDateKey,\n\t\tProductKey,\n\t\tCustomerKey,\n\t\tResellerKey,\n\t\tSalesOrderLineKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Sales\nReseller, Sales join(Reseller@ResellerKey === Sales@ResellerKey,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSales\nSalesTerritorySource aggregate(groupBy(SalesTerritoryKey),\n\tGroup = last(Group),\n\t\tCountry = last(Country),\n\t\tRegion = last(Region)) ~> Deduplicated1SalesTerritorySource\nDeduplicated1SalesTerritorySource select(mapColumn(\n\t\tGroup,\n\t\tCountry,\n\t\tRegion,\n\t\tSalesTerritoryKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SalesTerritory\nJoinSales, SalesTerritory join(Sales@SalesTerritoryKey === SalesTerritory@SalesTerritoryKey,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSalesTerritory\nJoinSalesTerritory select(mapColumn(\n\t\tBusinessTypeAlias = BusinessType,\n\t\tReseller_ResellerKey_Generated = Reseller@ResellerKey,\n\t\tResellerId,\n\t\tReseller,\n\t\tSalesTerritory_SalesTerritoryKey_Generated = SalesTerritory@SalesTerritoryKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectJoinSalesTerritory\nTargetChannelType aggregate(groupBy(ChannelTypeId),\n\tChannelTypeName = last(ChannelTypeName)) ~> Deduplicated1TargetChannelType\nDeduplicated1TargetChannelType select(mapColumn(\n\t\tChannelTypeId,\n\t\tChannelTypeNameAlias = ChannelTypeName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectChannelType\nSelectJoinSalesTerritory, SelectChannelType join(BusinessTypeAlias === ChannelTypeNameAlias,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinForChannelTypeId\nJoinForChannelTypeId select(mapColumn(\n\t\tBusinessTypeAlias,\n\t\tReseller_ResellerKey_Generated,\n\t\tResellerId,\n\t\tReseller,\n\t\tSalesTerritory_SalesTerritoryKey_Generated,\n\t\tChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectForChannelTypeId\nSelectForChannelTypeId select(mapColumn(\n\t\tChannelId = Reseller_ResellerKey_Generated,\n\t\tChannelKey = ResellerId,\n\t\tChannelName = Reseller,\n\t\tTerritoryId = SalesTerritory_SalesTerritoryKey_Generated,\n\t\tChannelTypeId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Channel\nChannel sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Channel',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> ChannelSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Country2_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ResellerDeltaSource"
						},
						{
							"name": "TargetCountry"
						}
					],
					"sinks": [
						{
							"name": "CountrySink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1ResellerDeltaSource"
						},
						{
							"name": "Reseller"
						},
						{
							"name": "SelectReseller"
						},
						{
							"name": "PreSKSelectCountry"
						},
						{
							"name": "Deduplicated1PreSKSelectCountry"
						},
						{
							"name": "SelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "Deduplicated1TargetCountry"
						},
						{
							"name": "SelectDeduplicated1TargetCountry"
						},
						{
							"name": "SelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "JoinSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "FilterInsertCountry"
						},
						{
							"name": "InsertCountry"
						},
						{
							"name": "SkCountry"
						},
						{
							"name": "AggregatedSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "MaxSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "JoinMaxSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "DerivedCountry"
						},
						{
							"name": "PostSkCountry"
						},
						{
							"name": "FilterUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "UpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "UnionUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "SelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "FinalCountry"
						},
						{
							"name": "Country"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tPostalCode as string,\n\t\tCountryRegion as string,\n\t\tStateProvince as string,\n\t\tCity as string,\n\t\tReseller as string,\n\t\tBusinessType as string,\n\t\tResellerId as string,\n\t\tResellerKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Reseller',\n\tmanifestType: 'manifest') ~> ResellerDeltaSource\nsource(output(\n\t\tCountryId as integer,\n\t\tIsoCountryName as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Country',\n\tmanifestType: 'manifest') ~> TargetCountry\nResellerDeltaSource aggregate(groupBy(ResellerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tReseller = last(Reseller),\n\t\tBusinessType = last(BusinessType),\n\t\tResellerId = last(ResellerId)) ~> Deduplicated1ResellerDeltaSource\nDeduplicated1ResellerDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tReseller,\n\t\tBusinessType,\n\t\tResellerId,\n\t\tResellerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Reseller\nReseller select(mapColumn(\n\t\tCountryRegion\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectReseller\nSelectReseller select(mapColumn(\n\t\tIsoCountryName = CountryRegion\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PreSKSelectCountry\nPreSKSelectCountry aggregate(groupBy(IsoCountryName),\n\tCount = count(1)) ~> Deduplicated1PreSKSelectCountry\nDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tIsoCountryName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1PreSKSelectCountry\nTargetCountry aggregate(groupBy(CountryId),\n\tIsoCountryName = last(IsoCountryName)) ~> Deduplicated1TargetCountry\nDeduplicated1TargetCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1TargetCountry\nSelectDeduplicated1TargetCountry select(mapColumn(\n\t\tTarIsoCountryName = IsoCountryName,\n\t\tTarCountryId = CountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarSelectDeduplicated1TargetCountry\nSelectDeduplicated1PreSKSelectCountry, SelectTarSelectDeduplicated1TargetCountry join(IsoCountryName === TarIsoCountryName,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarSelectDeduplicated1TargetCountry\nJoinSelectTarSelectDeduplicated1TargetCountry filter(isNull(TarCountryId)) ~> FilterInsertCountry\nFilterInsertCountry select(mapColumn(\n\t\tIsoCountryName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> InsertCountry\nInsertCountry keyGenerate(output(Sk_CountryId as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SkCountry\nSelectTarSelectDeduplicated1TargetCountry aggregate(Max_TarCountryId = max(toInteger(TarCountryId)) + 0) ~> AggregatedSelectTarSelectDeduplicated1TargetCountry\nAggregatedSelectTarSelectDeduplicated1TargetCountry derive(Max_TarCountryId = iif(isNull(Max_TarCountryId),0,Max_TarCountryId)) ~> MaxSelectTarSelectDeduplicated1TargetCountry\nSkCountry, MaxSelectTarSelectDeduplicated1TargetCountry join(true() === true(),\n\tjoinType:'cross',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinMaxSelectTarSelectDeduplicated1TargetCountry\nJoinMaxSelectTarSelectDeduplicated1TargetCountry derive(CountryId = Sk_CountryId + Max_TarCountryId) ~> DerivedCountry\nDerivedCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PostSkCountry\nJoinSelectTarSelectDeduplicated1TargetCountry filter(!isNull(TarCountryId)) ~> FilterUpdateSelectDeduplicated1PreSKSelectCountry\nFilterUpdateSelectDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId = TarCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> UpdateSelectDeduplicated1PreSKSelectCountry\nPostSkCountry, UpdateSelectDeduplicated1PreSKSelectCountry union(byName: true)~> UnionUpdateSelectDeduplicated1PreSKSelectCountry\nUnionUpdateSelectDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tTarIsoCountryName = IsoCountryName,\n\t\tTarCountryId = CountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry\nPreSKSelectCountry, SelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry join(IsoCountryName === TarIsoCountryName,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry\nJoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId = TarCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> FinalCountry\nFinalCountry aggregate(groupBy(CountryId),\n\tIsoCountryName = last(IsoCountryName)) ~> Country\nCountry sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Country',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> CountrySink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Country_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "CustomerDataDeltaSource"
						},
						{
							"name": "TargetCountry"
						}
					],
					"sinks": [
						{
							"name": "CountrySink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1CustomerDataDeltaSource"
						},
						{
							"name": "CustomerData"
						},
						{
							"name": "SelectCustomerData"
						},
						{
							"name": "PreSKSelectCountry"
						},
						{
							"name": "Deduplicated1PreSKSelectCountry"
						},
						{
							"name": "SelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "Deduplicated1TargetCountry"
						},
						{
							"name": "SelectDeduplicated1TargetCountry"
						},
						{
							"name": "SelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "JoinSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "FilterInsertCountry"
						},
						{
							"name": "InsertCountry"
						},
						{
							"name": "SkCountry"
						},
						{
							"name": "AggregatedSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "MaxSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "JoinMaxSelectTarSelectDeduplicated1TargetCountry"
						},
						{
							"name": "DerivedCountry"
						},
						{
							"name": "PostSkCountry"
						},
						{
							"name": "FilterUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "UpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "UnionUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "SelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry"
						},
						{
							"name": "FinalCountry"
						},
						{
							"name": "Country"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tCustomerKey as integer,\n\t\tCustomerId as string,\n\t\tCustomer as string,\n\t\tCity as string,\n\t\tStateProvince as string,\n\t\tCountryRegion as string,\n\t\tPostalCode as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'CustomerData',\n\tmanifestType: 'manifest') ~> CustomerDataDeltaSource\nsource(output(\n\t\tCountryId as integer,\n\t\tIsoCountryName as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Country',\n\tmanifestType: 'manifest') ~> TargetCountry\nCustomerDataDeltaSource aggregate(groupBy(CustomerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tCustomer = last(Customer),\n\t\tCustomerId = last(CustomerId)) ~> Deduplicated1CustomerDataDeltaSource\nDeduplicated1CustomerDataDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tCustomer,\n\t\tCustomerId,\n\t\tCustomerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> CustomerData\nCustomerData select(mapColumn(\n\t\tCountryRegion\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectCustomerData\nSelectCustomerData select(mapColumn(\n\t\tIsoCountryName = CountryRegion\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PreSKSelectCountry\nPreSKSelectCountry aggregate(groupBy(IsoCountryName),\n\tCount = count(1)) ~> Deduplicated1PreSKSelectCountry\nDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tIsoCountryName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1PreSKSelectCountry\nTargetCountry aggregate(groupBy(CountryId),\n\tIsoCountryName = last(IsoCountryName)) ~> Deduplicated1TargetCountry\nDeduplicated1TargetCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1TargetCountry\nSelectDeduplicated1TargetCountry select(mapColumn(\n\t\tTarIsoCountryName = IsoCountryName,\n\t\tTarCountryId = CountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarSelectDeduplicated1TargetCountry\nSelectDeduplicated1PreSKSelectCountry, SelectTarSelectDeduplicated1TargetCountry join(IsoCountryName === TarIsoCountryName,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarSelectDeduplicated1TargetCountry\nJoinSelectTarSelectDeduplicated1TargetCountry filter(isNull(TarCountryId)) ~> FilterInsertCountry\nFilterInsertCountry select(mapColumn(\n\t\tIsoCountryName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> InsertCountry\nInsertCountry keyGenerate(output(Sk_CountryId as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SkCountry\nSelectTarSelectDeduplicated1TargetCountry aggregate(Max_TarCountryId = max(toInteger(TarCountryId)) + 0) ~> AggregatedSelectTarSelectDeduplicated1TargetCountry\nAggregatedSelectTarSelectDeduplicated1TargetCountry derive(Max_TarCountryId = iif(isNull(Max_TarCountryId),0,Max_TarCountryId)) ~> MaxSelectTarSelectDeduplicated1TargetCountry\nSkCountry, MaxSelectTarSelectDeduplicated1TargetCountry join(true() === true(),\n\tjoinType:'cross',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinMaxSelectTarSelectDeduplicated1TargetCountry\nJoinMaxSelectTarSelectDeduplicated1TargetCountry derive(CountryId = Sk_CountryId + Max_TarCountryId) ~> DerivedCountry\nDerivedCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PostSkCountry\nJoinSelectTarSelectDeduplicated1TargetCountry filter(!isNull(TarCountryId)) ~> FilterUpdateSelectDeduplicated1PreSKSelectCountry\nFilterUpdateSelectDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId = TarCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> UpdateSelectDeduplicated1PreSKSelectCountry\nPostSkCountry, UpdateSelectDeduplicated1PreSKSelectCountry union(byName: true)~> UnionUpdateSelectDeduplicated1PreSKSelectCountry\nUnionUpdateSelectDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tTarIsoCountryName = IsoCountryName,\n\t\tTarCountryId = CountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry\nPreSKSelectCountry, SelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry join(IsoCountryName === TarIsoCountryName,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry\nJoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectCountry select(mapColumn(\n\t\tIsoCountryName,\n\t\tCountryId = TarCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> FinalCountry\nFinalCountry aggregate(groupBy(CountryId),\n\tIsoCountryName = last(IsoCountryName)) ~> Country\nCountry sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Country',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> CountrySink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Customer_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "CustomerDataDeltaSource"
						},
						{
							"name": "TargetCountry"
						},
						{
							"name": "TargetLocation"
						}
					],
					"sinks": [
						{
							"name": "CustomerSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1CustomerDataDeltaSource"
						},
						{
							"name": "CustomerData"
						},
						{
							"name": "SelectCustomerData"
						},
						{
							"name": "Deduplicated1TargetCountry"
						},
						{
							"name": "SelectCountry"
						},
						{
							"name": "JoinForCountryIdLookupFunction"
						},
						{
							"name": "SelectForCountryIdLookupFunction"
						},
						{
							"name": "Deduplicated1TargetLocation"
						},
						{
							"name": "SelectLocation"
						},
						{
							"name": "JoinForLocationId"
						},
						{
							"name": "SelectForLocationId"
						},
						{
							"name": "Customer"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tCustomerKey as integer,\n\t\tCustomerId as string,\n\t\tCustomer as string,\n\t\tCity as string,\n\t\tStateProvince as string,\n\t\tCountryRegion as string,\n\t\tPostalCode as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'CustomerData',\n\tmanifestType: 'manifest') ~> CustomerDataDeltaSource\nsource(output(\n\t\tCountryId as integer,\n\t\tIsoCountryName as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Country',\n\tmanifestType: 'manifest') ~> TargetCountry\nsource(output(\n\t\tLocationId as integer,\n\t\tLocationCity as string,\n\t\tLocationState as string,\n\t\tCountryId as integer,\n\t\tLocationZip as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Location',\n\tmanifestType: 'manifest') ~> TargetLocation\nCustomerDataDeltaSource aggregate(groupBy(CustomerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tCustomer = last(Customer),\n\t\tCustomerId = last(CustomerId)) ~> Deduplicated1CustomerDataDeltaSource\nDeduplicated1CustomerDataDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tCustomer,\n\t\tCustomerId,\n\t\tCustomerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> CustomerData\nCustomerData select(mapColumn(\n\t\tPostalCodeAlias = PostalCode,\n\t\tStateProvinceAlias = StateProvince,\n\t\tCityAlias = City,\n\t\tCountryRegionAlias = CountryRegion,\n\t\tCustomerId,\n\t\tCustomerData_CustomerKey_Generated = CustomerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectCustomerData\nTargetCountry aggregate(groupBy(CountryId),\n\tIsoCountryName = last(IsoCountryName)) ~> Deduplicated1TargetCountry\nDeduplicated1TargetCountry select(mapColumn(\n\t\tCountryIdLookupFunction = CountryId,\n\t\tIsoCountryNameAlias = IsoCountryName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectCountry\nSelectCustomerData, SelectCountry join(CountryRegionAlias === IsoCountryNameAlias,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinForCountryIdLookupFunction\nJoinForCountryIdLookupFunction select(mapColumn(\n\t\tPostalCodeAlias,\n\t\tStateProvinceAlias,\n\t\tCityAlias,\n\t\tCountryRegionAlias,\n\t\tCustomerId,\n\t\tCustomerData_CustomerKey_Generated,\n\t\tCountryIdLookupFunction\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectForCountryIdLookupFunction\nTargetLocation aggregate(groupBy(LocationId),\n\tLocationCity = last(LocationCity),\n\t\tCountryId = last(CountryId),\n\t\tLocationZip = last(LocationZip),\n\t\tLocationState = last(LocationState)) ~> Deduplicated1TargetLocation\nDeduplicated1TargetLocation select(mapColumn(\n\t\tLocationId,\n\t\tLocationZipAlias = LocationZip,\n\t\tLocationStateAlias = LocationState,\n\t\tLocationCityAlias = LocationCity,\n\t\tCountryIdAlias = CountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectLocation\nSelectForCountryIdLookupFunction, SelectLocation join(PostalCodeAlias === LocationZipAlias\n\t&& StateProvinceAlias === LocationStateAlias\n\t&& CityAlias === LocationCityAlias\n\t&& CountryIdLookupFunction === CountryIdAlias,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinForLocationId\nJoinForLocationId select(mapColumn(\n\t\tPostalCodeAlias,\n\t\tStateProvinceAlias,\n\t\tCityAlias,\n\t\tCountryRegionAlias,\n\t\tCustomerId,\n\t\tCustomerData_CustomerKey_Generated,\n\t\tLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectForLocationId\nSelectForLocationId select(mapColumn(\n\t\tLocationId,\n\t\tCustomerKey = CustomerId,\n\t\tCustomerId = CustomerData_CustomerKey_Generated\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Customer\nCustomer sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Customer',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> CustomerSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/IndividualCustomer_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "CustomerDataDeltaSource"
						}
					],
					"sinks": [
						{
							"name": "IndividualCustomerSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1CustomerDataDeltaSource"
						},
						{
							"name": "CustomerData"
						},
						{
							"name": "SelectCustomerData"
						},
						{
							"name": "IndividualCustomer"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tCustomerKey as integer,\n\t\tCustomerId as string,\n\t\tCustomer as string,\n\t\tCity as string,\n\t\tStateProvince as string,\n\t\tCountryRegion as string,\n\t\tPostalCode as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'CustomerData',\n\tmanifestType: 'manifest') ~> CustomerDataDeltaSource\nCustomerDataDeltaSource aggregate(groupBy(CustomerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tCustomer = last(Customer),\n\t\tCustomerId = last(CustomerId)) ~> Deduplicated1CustomerDataDeltaSource\nDeduplicated1CustomerDataDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tCustomer,\n\t\tCustomerId,\n\t\tCustomerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> CustomerData\nCustomerData select(mapColumn(\n\t\tCustomerKey,\n\t\tCustomer\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectCustomerData\nSelectCustomerData select(mapColumn(\n\t\tCustomerId = CustomerKey,\n\t\tIndividualCustomerName = Customer\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> IndividualCustomer\nIndividualCustomer sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'IndividualCustomer',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> IndividualCustomerSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Item_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ProductDataDeltaSource"
						}
					],
					"sinks": [
						{
							"name": "ItemSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1ProductDataDeltaSource"
						},
						{
							"name": "ProductData"
						},
						{
							"name": "SelectProductData"
						},
						{
							"name": "Item"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tCategory as string,\n\t\tSubcategory as string,\n\t\tModel as string,\n\t\tListPrice as decimal(18,2),\n\t\tColor as string,\n\t\tStandardCost as decimal(18,2),\n\t\tProduct as string,\n\t\tSKU as string,\n\t\tProductKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'ProductData',\n\tmanifestType: 'manifest') ~> ProductDataDeltaSource\nProductDataDeltaSource aggregate(groupBy(ProductKey),\n\tCategory = last(Category),\n\t\tSubcategory = last(Subcategory),\n\t\tModel = last(Model),\n\t\tListPrice = last(ListPrice),\n\t\tColor = last(Color),\n\t\tStandardCost = last(StandardCost),\n\t\tProduct = last(Product),\n\t\tSKU = last(SKU)) ~> Deduplicated1ProductDataDeltaSource\nDeduplicated1ProductDataDeltaSource select(mapColumn(\n\t\tCategory,\n\t\tSubcategory,\n\t\tModel,\n\t\tListPrice,\n\t\tColor,\n\t\tStandardCost,\n\t\tProduct,\n\t\tSKU,\n\t\tProductKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> ProductData\nProductData select(mapColumn(\n\t\tSKU,\n\t\tStandardCost,\n\t\tListPrice\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectProductData\nSelectProductData select(mapColumn(\n\t\tItemSku = SKU,\n\t\tStandardCost,\n\t\tListPrice\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Item\nItem sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Item',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> ItemSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Location2_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ResellerDeltaSource"
						},
						{
							"name": "TargetCountry"
						},
						{
							"name": "TargetLocation"
						}
					],
					"sinks": [
						{
							"name": "LocationSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1ResellerDeltaSource"
						},
						{
							"name": "Reseller"
						},
						{
							"name": "SelectReseller"
						},
						{
							"name": "Deduplicated1TargetCountry"
						},
						{
							"name": "SelectCountry"
						},
						{
							"name": "JoinForCountryId"
						},
						{
							"name": "SelectForCountryId"
						},
						{
							"name": "PreSKSelectLocation"
						},
						{
							"name": "Deduplicated1PreSKSelectLocation"
						},
						{
							"name": "SelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "Deduplicated1TargetLocation"
						},
						{
							"name": "SelectDeduplicated1TargetLocation"
						},
						{
							"name": "SelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "JoinSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "FilterInsertLocation"
						},
						{
							"name": "InsertLocation"
						},
						{
							"name": "SkLocation"
						},
						{
							"name": "AggregatedSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "MaxSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "JoinMaxSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "DerivedLocation"
						},
						{
							"name": "PostSkLocation"
						},
						{
							"name": "FilterUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "UpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "UnionUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "SelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "FinalLocation"
						},
						{
							"name": "Location"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tPostalCode as string,\n\t\tCountryRegion as string,\n\t\tStateProvince as string,\n\t\tCity as string,\n\t\tReseller as string,\n\t\tBusinessType as string,\n\t\tResellerId as string,\n\t\tResellerKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Reseller',\n\tmanifestType: 'manifest') ~> ResellerDeltaSource\nsource(output(\n\t\tCountryId as integer,\n\t\tIsoCountryName as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Country',\n\tmanifestType: 'manifest') ~> TargetCountry\nsource(output(\n\t\tLocationId as integer,\n\t\tLocationCity as string,\n\t\tLocationState as string,\n\t\tCountryId as integer,\n\t\tLocationZip as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Location',\n\tmanifestType: 'manifest') ~> TargetLocation\nResellerDeltaSource aggregate(groupBy(ResellerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tReseller = last(Reseller),\n\t\tBusinessType = last(BusinessType),\n\t\tResellerId = last(ResellerId)) ~> Deduplicated1ResellerDeltaSource\nDeduplicated1ResellerDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tReseller,\n\t\tBusinessType,\n\t\tResellerId,\n\t\tResellerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Reseller\nReseller select(mapColumn(\n\t\tCountryRegionAlias = CountryRegion,\n\t\tPostalCode,\n\t\tStateProvince,\n\t\tCity\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectReseller\nTargetCountry aggregate(groupBy(CountryId),\n\tIsoCountryName = last(IsoCountryName)) ~> Deduplicated1TargetCountry\nDeduplicated1TargetCountry select(mapColumn(\n\t\tCountryId,\n\t\tIsoCountryNameAlias = IsoCountryName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectCountry\nSelectReseller, SelectCountry join(CountryRegionAlias === IsoCountryNameAlias,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinForCountryId\nJoinForCountryId select(mapColumn(\n\t\tCountryRegionAlias,\n\t\tPostalCode,\n\t\tStateProvince,\n\t\tCity,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectForCountryId\nSelectForCountryId select(mapColumn(\n\t\tLocationZip = PostalCode,\n\t\tLocationState = StateProvince,\n\t\tLocationCity = City,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PreSKSelectLocation\nPreSKSelectLocation aggregate(groupBy(LocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip),\n\tCount = count(1)) ~> Deduplicated1PreSKSelectLocation\nDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1PreSKSelectLocation\nTargetLocation aggregate(groupBy(LocationId),\n\tLocationZip = last(LocationZip),\n\t\tLocationState = last(LocationState),\n\t\tLocationCity = last(LocationCity),\n\t\tCountryId = last(CountryId)) ~> Deduplicated1TargetLocation\nDeduplicated1TargetLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip,\n\t\tLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1TargetLocation\nSelectDeduplicated1TargetLocation select(mapColumn(\n\t\tTarLocationCity = LocationCity,\n\t\tTarLocationState = LocationState,\n\t\tTarCountryId = CountryId,\n\t\tTarLocationZip = LocationZip,\n\t\tTarLocationId = LocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarSelectDeduplicated1TargetLocation\nSelectDeduplicated1PreSKSelectLocation, SelectTarSelectDeduplicated1TargetLocation join(LocationCity === TarLocationCity\n\t&& LocationState === TarLocationState\n\t&& CountryId === TarCountryId\n\t&& LocationZip === TarLocationZip,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarSelectDeduplicated1TargetLocation\nJoinSelectTarSelectDeduplicated1TargetLocation filter(isNull(TarLocationId)) ~> FilterInsertLocation\nFilterInsertLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> InsertLocation\nInsertLocation keyGenerate(output(Sk_LocationId as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SkLocation\nSelectTarSelectDeduplicated1TargetLocation aggregate(Max_TarLocationId = max(toInteger(TarLocationId)) + 0) ~> AggregatedSelectTarSelectDeduplicated1TargetLocation\nAggregatedSelectTarSelectDeduplicated1TargetLocation derive(Max_TarLocationId = iif(isNull(Max_TarLocationId),0,Max_TarLocationId)) ~> MaxSelectTarSelectDeduplicated1TargetLocation\nSkLocation, MaxSelectTarSelectDeduplicated1TargetLocation join(true() === true(),\n\tjoinType:'cross',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinMaxSelectTarSelectDeduplicated1TargetLocation\nJoinMaxSelectTarSelectDeduplicated1TargetLocation derive(LocationId = Sk_LocationId + Max_TarLocationId) ~> DerivedLocation\nDerivedLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip,\n\t\tLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PostSkLocation\nJoinSelectTarSelectDeduplicated1TargetLocation filter(!isNull(TarLocationId)) ~> FilterUpdateSelectDeduplicated1PreSKSelectLocation\nFilterUpdateSelectDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip,\n\t\tLocationId = TarLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> UpdateSelectDeduplicated1PreSKSelectLocation\nPostSkLocation, UpdateSelectDeduplicated1PreSKSelectLocation union(byName: true)~> UnionUpdateSelectDeduplicated1PreSKSelectLocation\nUnionUpdateSelectDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tTarLocationCity = LocationCity,\n\t\tTarLocationState = LocationState,\n\t\tTarCountryId = CountryId,\n\t\tTarLocationZip = LocationZip,\n\t\tTarLocationId = LocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation\nPreSKSelectLocation, SelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation join(LocationCity === TarLocationCity\n\t&& LocationState === TarLocationState\n\t&& CountryId === TarCountryId\n\t&& LocationZip === TarLocationZip,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation\nJoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tLocationZip,\n\t\tLocationState,\n\t\tLocationCity,\n\t\tCountryId,\n\t\tLocationId = TarLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> FinalLocation\nFinalLocation aggregate(groupBy(LocationId),\n\tLocationZip = last(LocationZip),\n\t\tLocationState = last(LocationState),\n\t\tLocationCity = last(LocationCity),\n\t\tCountryId = last(CountryId)) ~> Location\nLocation sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Location',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> LocationSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Location_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "CustomerDataDeltaSource"
						},
						{
							"name": "TargetCountry"
						},
						{
							"name": "TargetLocation"
						}
					],
					"sinks": [
						{
							"name": "LocationSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1CustomerDataDeltaSource"
						},
						{
							"name": "CustomerData"
						},
						{
							"name": "SelectCustomerData"
						},
						{
							"name": "Deduplicated1TargetCountry"
						},
						{
							"name": "SelectCountry"
						},
						{
							"name": "JoinForCountryId"
						},
						{
							"name": "SelectForCountryId"
						},
						{
							"name": "PreSKSelectLocation"
						},
						{
							"name": "Deduplicated1PreSKSelectLocation"
						},
						{
							"name": "SelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "Deduplicated1TargetLocation"
						},
						{
							"name": "SelectDeduplicated1TargetLocation"
						},
						{
							"name": "SelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "JoinSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "FilterInsertLocation"
						},
						{
							"name": "InsertLocation"
						},
						{
							"name": "SkLocation"
						},
						{
							"name": "AggregatedSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "MaxSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "JoinMaxSelectTarSelectDeduplicated1TargetLocation"
						},
						{
							"name": "DerivedLocation"
						},
						{
							"name": "PostSkLocation"
						},
						{
							"name": "FilterUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "UpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "UnionUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "SelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation"
						},
						{
							"name": "FinalLocation"
						},
						{
							"name": "Location"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tCustomerKey as integer,\n\t\tCustomerId as string,\n\t\tCustomer as string,\n\t\tCity as string,\n\t\tStateProvince as string,\n\t\tCountryRegion as string,\n\t\tPostalCode as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'CustomerData',\n\tmanifestType: 'manifest') ~> CustomerDataDeltaSource\nsource(output(\n\t\tCountryId as integer,\n\t\tIsoCountryName as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Country',\n\tmanifestType: 'manifest') ~> TargetCountry\nsource(output(\n\t\tLocationId as integer,\n\t\tLocationCity as string,\n\t\tLocationState as string,\n\t\tCountryId as integer,\n\t\tLocationZip as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Location',\n\tmanifestType: 'manifest') ~> TargetLocation\nCustomerDataDeltaSource aggregate(groupBy(CustomerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tCustomer = last(Customer),\n\t\tCustomerId = last(CustomerId)) ~> Deduplicated1CustomerDataDeltaSource\nDeduplicated1CustomerDataDeltaSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tCustomer,\n\t\tCustomerId,\n\t\tCustomerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> CustomerData\nCustomerData select(mapColumn(\n\t\tCountryRegionAlias = CountryRegion,\n\t\tPostalCode,\n\t\tStateProvince,\n\t\tCity\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectCustomerData\nTargetCountry aggregate(groupBy(CountryId),\n\tIsoCountryName = last(IsoCountryName)) ~> Deduplicated1TargetCountry\nDeduplicated1TargetCountry select(mapColumn(\n\t\tCountryId,\n\t\tIsoCountryNameAlias = IsoCountryName\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectCountry\nSelectCustomerData, SelectCountry join(CountryRegionAlias === IsoCountryNameAlias,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinForCountryId\nJoinForCountryId select(mapColumn(\n\t\tCountryRegionAlias,\n\t\tPostalCode,\n\t\tStateProvince,\n\t\tCity,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectForCountryId\nSelectForCountryId select(mapColumn(\n\t\tLocationZip = PostalCode,\n\t\tLocationState = StateProvince,\n\t\tLocationCity = City,\n\t\tCountryId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PreSKSelectLocation\nPreSKSelectLocation aggregate(groupBy(LocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip),\n\tCount = count(1)) ~> Deduplicated1PreSKSelectLocation\nDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1PreSKSelectLocation\nTargetLocation aggregate(groupBy(LocationId),\n\tLocationZip = last(LocationZip),\n\t\tLocationState = last(LocationState),\n\t\tLocationCity = last(LocationCity),\n\t\tCountryId = last(CountryId)) ~> Deduplicated1TargetLocation\nDeduplicated1TargetLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip,\n\t\tLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectDeduplicated1TargetLocation\nSelectDeduplicated1TargetLocation select(mapColumn(\n\t\tTarLocationCity = LocationCity,\n\t\tTarLocationState = LocationState,\n\t\tTarCountryId = CountryId,\n\t\tTarLocationZip = LocationZip,\n\t\tTarLocationId = LocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarSelectDeduplicated1TargetLocation\nSelectDeduplicated1PreSKSelectLocation, SelectTarSelectDeduplicated1TargetLocation join(LocationCity === TarLocationCity\n\t&& LocationState === TarLocationState\n\t&& CountryId === TarCountryId\n\t&& LocationZip === TarLocationZip,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarSelectDeduplicated1TargetLocation\nJoinSelectTarSelectDeduplicated1TargetLocation filter(isNull(TarLocationId)) ~> FilterInsertLocation\nFilterInsertLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> InsertLocation\nInsertLocation keyGenerate(output(Sk_LocationId as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SkLocation\nSelectTarSelectDeduplicated1TargetLocation aggregate(Max_TarLocationId = max(toInteger(TarLocationId)) + 0) ~> AggregatedSelectTarSelectDeduplicated1TargetLocation\nAggregatedSelectTarSelectDeduplicated1TargetLocation derive(Max_TarLocationId = iif(isNull(Max_TarLocationId),0,Max_TarLocationId)) ~> MaxSelectTarSelectDeduplicated1TargetLocation\nSkLocation, MaxSelectTarSelectDeduplicated1TargetLocation join(true() === true(),\n\tjoinType:'cross',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinMaxSelectTarSelectDeduplicated1TargetLocation\nJoinMaxSelectTarSelectDeduplicated1TargetLocation derive(LocationId = Sk_LocationId + Max_TarLocationId) ~> DerivedLocation\nDerivedLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip,\n\t\tLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> PostSkLocation\nJoinSelectTarSelectDeduplicated1TargetLocation filter(!isNull(TarLocationId)) ~> FilterUpdateSelectDeduplicated1PreSKSelectLocation\nFilterUpdateSelectDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tLocationCity,\n\t\tLocationState,\n\t\tCountryId,\n\t\tLocationZip,\n\t\tLocationId = TarLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> UpdateSelectDeduplicated1PreSKSelectLocation\nPostSkLocation, UpdateSelectDeduplicated1PreSKSelectLocation union(byName: true)~> UnionUpdateSelectDeduplicated1PreSKSelectLocation\nUnionUpdateSelectDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tTarLocationCity = LocationCity,\n\t\tTarLocationState = LocationState,\n\t\tTarCountryId = CountryId,\n\t\tTarLocationZip = LocationZip,\n\t\tTarLocationId = LocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation\nPreSKSelectLocation, SelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation join(LocationCity === TarLocationCity\n\t&& LocationState === TarLocationState\n\t&& CountryId === TarCountryId\n\t&& LocationZip === TarLocationZip,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation\nJoinSelectTarUnionUpdateSelectDeduplicated1PreSKSelectLocation select(mapColumn(\n\t\tLocationZip,\n\t\tLocationState,\n\t\tLocationCity,\n\t\tCountryId,\n\t\tLocationId = TarLocationId\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> FinalLocation\nFinalLocation aggregate(groupBy(LocationId),\n\tLocationZip = last(LocationZip),\n\t\tLocationState = last(LocationState),\n\t\tLocationCity = last(LocationCity),\n\t\tCountryId = last(CountryId)) ~> Location\nLocation sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Location',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> LocationSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ProductCategoryDim_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ProductDataDeltaSource"
						}
					],
					"sinks": [
						{
							"name": "ProductCategoryDimSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1ProductDataDeltaSource"
						},
						{
							"name": "ProductData"
						},
						{
							"name": "SelectProductData"
						},
						{
							"name": "ProductCategoryDim"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tCategory as string,\n\t\tSubcategory as string,\n\t\tModel as string,\n\t\tListPrice as decimal(18,2),\n\t\tColor as string,\n\t\tStandardCost as decimal(18,2),\n\t\tProduct as string,\n\t\tSKU as string,\n\t\tProductKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'ProductData',\n\tmanifestType: 'manifest') ~> ProductDataDeltaSource\nProductDataDeltaSource aggregate(groupBy(ProductKey),\n\tCategory = last(Category),\n\t\tSubcategory = last(Subcategory),\n\t\tModel = last(Model),\n\t\tListPrice = last(ListPrice),\n\t\tColor = last(Color),\n\t\tStandardCost = last(StandardCost),\n\t\tProduct = last(Product),\n\t\tSKU = last(SKU)) ~> Deduplicated1ProductDataDeltaSource\nDeduplicated1ProductDataDeltaSource select(mapColumn(\n\t\tCategory,\n\t\tSubcategory,\n\t\tModel,\n\t\tListPrice,\n\t\tColor,\n\t\tStandardCost,\n\t\tProduct,\n\t\tSKU,\n\t\tProductKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> ProductData\nProductData select(mapColumn(\n\t\tProductKey,\n\t\tModel,\n\t\tSubcategory,\n\t\tCategory\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectProductData\nSelectProductData select(mapColumn(\n\t\tProductId = ProductKey,\n\t\tModel,\n\t\tSubCategory = Subcategory,\n\t\tCategory\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> ProductCategoryDim\nProductCategoryDim sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'ProductCategoryDim',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> ProductCategoryDimSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Product_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ProductDataDeltaSource"
						}
					],
					"sinks": [
						{
							"name": "ProductSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1ProductDataDeltaSource"
						},
						{
							"name": "ProductData"
						},
						{
							"name": "SelectProductData"
						},
						{
							"name": "Product"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tCategory as string,\n\t\tSubcategory as string,\n\t\tModel as string,\n\t\tListPrice as decimal(18,2),\n\t\tColor as string,\n\t\tStandardCost as decimal(18,2),\n\t\tProduct as string,\n\t\tSKU as string,\n\t\tProductKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'ProductData',\n\tmanifestType: 'manifest') ~> ProductDataDeltaSource\nProductDataDeltaSource aggregate(groupBy(ProductKey),\n\tCategory = last(Category),\n\t\tSubcategory = last(Subcategory),\n\t\tModel = last(Model),\n\t\tListPrice = last(ListPrice),\n\t\tColor = last(Color),\n\t\tStandardCost = last(StandardCost),\n\t\tProduct = last(Product),\n\t\tSKU = last(SKU)) ~> Deduplicated1ProductDataDeltaSource\nDeduplicated1ProductDataDeltaSource select(mapColumn(\n\t\tCategory,\n\t\tSubcategory,\n\t\tModel,\n\t\tListPrice,\n\t\tColor,\n\t\tStandardCost,\n\t\tProduct,\n\t\tSKU,\n\t\tProductKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> ProductData\nProductData select(mapColumn(\n\t\tProductKey,\n\t\tSKU,\n\t\tProduct,\n\t\tColor\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectProductData\nSelectProductData select(mapColumn(\n\t\tProductId = ProductKey,\n\t\tItemSku = SKU,\n\t\tProductName = Product,\n\t\tProductColor = Color\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Product\nProduct sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Product',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> ProductSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Territory_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "SalesTerritoryDeltaSource"
						}
					],
					"sinks": [
						{
							"name": "TerritorySink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1SalesTerritoryDeltaSource"
						},
						{
							"name": "SalesTerritory"
						},
						{
							"name": "SelectSalesTerritory"
						},
						{
							"name": "Territory"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tSalesTerritoryKey as integer,\n\t\tRegion as string,\n\t\tCountry as string,\n\t\tGroup as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'SalesTerritory',\n\tmanifestType: 'manifest') ~> SalesTerritoryDeltaSource\nSalesTerritoryDeltaSource aggregate(groupBy(SalesTerritoryKey),\n\tGroup = last(Group),\n\t\tCountry = last(Country),\n\t\tRegion = last(Region)) ~> Deduplicated1SalesTerritoryDeltaSource\nDeduplicated1SalesTerritoryDeltaSource select(mapColumn(\n\t\tGroup,\n\t\tCountry,\n\t\tRegion,\n\t\tSalesTerritoryKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SalesTerritory\nSalesTerritory select(mapColumn(\n\t\tGroup,\n\t\tCountry,\n\t\tRegion,\n\t\tSalesTerritoryKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectSalesTerritory\nSelectSalesTerritory select(mapColumn(\n\t\tGroup,\n\t\tCountry,\n\t\tRegion,\n\t\tTerritoryId = SalesTerritoryKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Territory\nTerritory sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Territory',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> TerritorySink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TransactionLineItem_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "SalesDeltaSource"
						},
						{
							"name": "SalesOrderSource"
						}
					],
					"sinks": [
						{
							"name": "TransactionLineItemSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1SalesDeltaSource"
						},
						{
							"name": "Sales"
						},
						{
							"name": "Deduplicated1SalesOrderSource"
						},
						{
							"name": "SalesOrder"
						},
						{
							"name": "JoinSalesOrder"
						},
						{
							"name": "SelectJoinSalesOrder"
						},
						{
							"name": "TransactionLineItem"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tSalesAmount as decimal(18,2),\n\t\tTotalProductCost as decimal(18,2),\n\t\tProductStandardCost as decimal(18,2),\n\t\tUnitPriceDiscountPct as decimal(18,2),\n\t\tExtendedAmount as decimal(18,2),\n\t\tUnitPrice as decimal(18,2),\n\t\tOrderQuantity as integer,\n\t\tSalesTerritoryKey as integer,\n\t\tShipDateKey as integer,\n\t\tDueDateKey as integer,\n\t\tOrderDateKey as integer,\n\t\tProductKey as integer,\n\t\tCustomerKey as integer,\n\t\tResellerKey as integer,\n\t\tSalesOrderLineKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Sales',\n\tmanifestType: 'manifest') ~> SalesDeltaSource\nsource(output(\n\t\tSalesOrderLine as string,\n\t\tSalesOrder as string,\n\t\tSalesOrderLineKey as integer,\n\t\tChannel as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'SalesOrder',\n\tmanifestType: 'manifest') ~> SalesOrderSource\nSalesDeltaSource aggregate(groupBy(ProductKey,\n\t\tCustomerKey,\n\t\tResellerKey,\n\t\tSalesOrderLineKey),\n\tSalesAmount = last(SalesAmount),\n\t\tTotalProductCost = last(TotalProductCost),\n\t\tProductStandardCost = last(ProductStandardCost),\n\t\tUnitPriceDiscountPct = last(UnitPriceDiscountPct),\n\t\tExtendedAmount = last(ExtendedAmount),\n\t\tUnitPrice = last(UnitPrice),\n\t\tOrderQuantity = last(OrderQuantity),\n\t\tSalesTerritoryKey = last(SalesTerritoryKey),\n\t\tShipDateKey = last(ShipDateKey),\n\t\tDueDateKey = last(DueDateKey),\n\t\tOrderDateKey = last(OrderDateKey)) ~> Deduplicated1SalesDeltaSource\nDeduplicated1SalesDeltaSource select(mapColumn(\n\t\tSalesAmount,\n\t\tTotalProductCost,\n\t\tProductStandardCost,\n\t\tUnitPriceDiscountPct,\n\t\tExtendedAmount,\n\t\tUnitPrice,\n\t\tOrderQuantity,\n\t\tSalesTerritoryKey,\n\t\tShipDateKey,\n\t\tDueDateKey,\n\t\tOrderDateKey,\n\t\tProductKey,\n\t\tCustomerKey,\n\t\tResellerKey,\n\t\tSalesOrderLineKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Sales\nSalesOrderSource aggregate(groupBy(SalesOrderLineKey),\n\tSalesOrderLine = last(SalesOrderLine),\n\t\tSalesOrder = last(SalesOrder),\n\t\tChannel = last(Channel)) ~> Deduplicated1SalesOrderSource\nDeduplicated1SalesOrderSource select(mapColumn(\n\t\tSalesOrderLine,\n\t\tSalesOrder,\n\t\tSalesOrderLineKey,\n\t\tChannel\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SalesOrder\nSales, SalesOrder join(Sales@SalesOrderLineKey === SalesOrder@SalesOrderLineKey,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSalesOrder\nJoinSalesOrder select(mapColumn(\n\t\tShipDateKey,\n\t\tDueDateKey,\n\t\tOrderDateKey,\n\t\tSalesOrder,\n\t\tSales_SalesOrderLineKey_Generated = Sales@SalesOrderLineKey,\n\t\tProductKey,\n\t\tOrderQuantity,\n\t\tUnitPrice,\n\t\tTotalProductCost,\n\t\tProductStandardCost,\n\t\tSalesAmount,\n\t\tUnitPriceDiscountPct\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectJoinSalesOrder\nSelectJoinSalesOrder select(mapColumn(\n\t\tShipDateKey,\n\t\tDueDateKey,\n\t\tOrderDateKey,\n\t\tTransactionId = SalesOrder,\n\t\tTransactionLineItemId = Sales_SalesOrderLineKey_Generated,\n\t\tProductId = ProductKey,\n\t\tQuantity = OrderQuantity,\n\t\tProductListPriceAmount = UnitPrice,\n\t\tTransactionProductPriceAmount = TotalProductCost,\n\t\tTotalTransactionLineItemAmount = ProductStandardCost,\n\t\tTotalTransactionSalesPriceAmount = SalesAmount,\n\t\tProductPriceAdjustmentPercentage = UnitPriceDiscountPct\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> TransactionLineItem\nTransactionLineItem sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'TransactionLineItem',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> TransactionLineItemSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Transaction_DataFlow1')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "AdventureWorksDataFlows"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "SalesOrderDeltaSource"
						},
						{
							"name": "SalesSource"
						},
						{
							"name": "CustomerDataSource"
						},
						{
							"name": "ResellerSource"
						}
					],
					"sinks": [
						{
							"name": "TransactionSink"
						}
					],
					"transformations": [
						{
							"name": "Deduplicated1SalesOrderDeltaSource"
						},
						{
							"name": "SalesOrder"
						},
						{
							"name": "Deduplicated1SalesSource"
						},
						{
							"name": "Sales"
						},
						{
							"name": "JoinSales"
						},
						{
							"name": "Deduplicated1CustomerDataSource"
						},
						{
							"name": "CustomerData"
						},
						{
							"name": "JoinCustomerData"
						},
						{
							"name": "Deduplicated1ResellerSource"
						},
						{
							"name": "Reseller"
						},
						{
							"name": "JoinReseller"
						},
						{
							"name": "SelectJoinReseller"
						},
						{
							"name": "Transaction"
						}
					],
					"script": "parameters{\n\tmodifiedAfter as timestamp,\n\tmodifiedBefore as timestamp\n}\nsource(output(\n\t\tSalesOrderLine as string,\n\t\tSalesOrder as string,\n\t\tSalesOrderLineKey as integer,\n\t\tChannel as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'SalesOrder',\n\tmanifestType: 'manifest') ~> SalesOrderDeltaSource\nsource(output(\n\t\tSalesAmount as decimal(18,2),\n\t\tTotalProductCost as decimal(18,2),\n\t\tProductStandardCost as decimal(18,2),\n\t\tUnitPriceDiscountPct as decimal(18,2),\n\t\tExtendedAmount as decimal(18,2),\n\t\tUnitPrice as decimal(18,2),\n\t\tOrderQuantity as integer,\n\t\tSalesTerritoryKey as integer,\n\t\tShipDateKey as integer,\n\t\tDueDateKey as integer,\n\t\tOrderDateKey as integer,\n\t\tProductKey as integer,\n\t\tCustomerKey as integer,\n\t\tResellerKey as integer,\n\t\tSalesOrderLineKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Sales',\n\tmanifestType: 'manifest') ~> SalesSource\nsource(output(\n\t\tCustomerKey as integer,\n\t\tCustomerId as string,\n\t\tCustomer as string,\n\t\tCity as string,\n\t\tStateProvince as string,\n\t\tCountryRegion as string,\n\t\tPostalCode as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'CustomerData',\n\tmanifestType: 'manifest') ~> CustomerDataSource\nsource(output(\n\t\tPostalCode as string,\n\t\tCountryRegion as string,\n\t\tStateProvince as string,\n\t\tCity as string,\n\t\tReseller as string,\n\t\tBusinessType as string,\n\t\tResellerId as string,\n\t\tResellerKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworks',\n\ttableName: 'Reseller',\n\tmanifestType: 'manifest') ~> ResellerSource\nSalesOrderDeltaSource aggregate(groupBy(SalesOrderLineKey),\n\tSalesOrderLine = last(SalesOrderLine),\n\t\tSalesOrder = last(SalesOrder),\n\t\tChannel = last(Channel)) ~> Deduplicated1SalesOrderDeltaSource\nDeduplicated1SalesOrderDeltaSource select(mapColumn(\n\t\tSalesOrderLine,\n\t\tSalesOrder,\n\t\tSalesOrderLineKey,\n\t\tChannel\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SalesOrder\nSalesSource aggregate(groupBy(ProductKey,\n\t\tCustomerKey,\n\t\tResellerKey,\n\t\tSalesOrderLineKey),\n\tSalesAmount = last(SalesAmount),\n\t\tTotalProductCost = last(TotalProductCost),\n\t\tProductStandardCost = last(ProductStandardCost),\n\t\tUnitPriceDiscountPct = last(UnitPriceDiscountPct),\n\t\tExtendedAmount = last(ExtendedAmount),\n\t\tUnitPrice = last(UnitPrice),\n\t\tOrderQuantity = last(OrderQuantity),\n\t\tSalesTerritoryKey = last(SalesTerritoryKey),\n\t\tShipDateKey = last(ShipDateKey),\n\t\tDueDateKey = last(DueDateKey),\n\t\tOrderDateKey = last(OrderDateKey)) ~> Deduplicated1SalesSource\nDeduplicated1SalesSource select(mapColumn(\n\t\tSalesAmount,\n\t\tTotalProductCost,\n\t\tProductStandardCost,\n\t\tUnitPriceDiscountPct,\n\t\tExtendedAmount,\n\t\tUnitPrice,\n\t\tOrderQuantity,\n\t\tSalesTerritoryKey,\n\t\tShipDateKey,\n\t\tDueDateKey,\n\t\tOrderDateKey,\n\t\tProductKey,\n\t\tCustomerKey,\n\t\tResellerKey,\n\t\tSalesOrderLineKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Sales\nSalesOrder, Sales join(SalesOrder@SalesOrderLineKey === Sales@SalesOrderLineKey,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinSales\nCustomerDataSource aggregate(groupBy(CustomerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tCustomer = last(Customer),\n\t\tCustomerId = last(CustomerId)) ~> Deduplicated1CustomerDataSource\nDeduplicated1CustomerDataSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tCustomer,\n\t\tCustomerId,\n\t\tCustomerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> CustomerData\nJoinSales, CustomerData join(Sales@CustomerKey === CustomerData@CustomerKey,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinCustomerData\nResellerSource aggregate(groupBy(ResellerKey),\n\tPostalCode = last(PostalCode),\n\t\tCountryRegion = last(CountryRegion),\n\t\tStateProvince = last(StateProvince),\n\t\tCity = last(City),\n\t\tReseller = last(Reseller),\n\t\tBusinessType = last(BusinessType),\n\t\tResellerId = last(ResellerId)) ~> Deduplicated1ResellerSource\nDeduplicated1ResellerSource select(mapColumn(\n\t\tPostalCode,\n\t\tCountryRegion,\n\t\tStateProvince,\n\t\tCity,\n\t\tReseller,\n\t\tBusinessType,\n\t\tResellerId,\n\t\tResellerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Reseller\nJoinCustomerData, Reseller join(Sales@ResellerKey === Reseller@ResellerKey,\n\tjoinType:'left',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> JoinReseller\nJoinReseller select(mapColumn(\n\t\tSalesOrder,\n\t\tCustomerData_CustomerKey_Generated = CustomerData@CustomerKey,\n\t\tReseller_ResellerKey_Generated = Reseller@ResellerKey\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> SelectJoinReseller\nSelectJoinReseller select(mapColumn(\n\t\tTransactionId = SalesOrder,\n\t\tCustomerId = CustomerData_CustomerKey_Generated,\n\t\tChannelId = Reseller_ResellerKey_Generated\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> Transaction\nTransaction sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tstore: 'synapse',\n\tdatabaseType: 'spark',\n\tformat: 'table',\n\tdatabase: 'adworkstarget',\n\ttableName: 'Transaction',\n\tpartitionBy('hash', 1),\n\tmanifestType: 'manifest') ~> TransactionSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchcustomerdaily')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "intpchcust",
								"type": "DatasetReference"
							},
							"name": "Customer"
						},
						{
							"dataset": {
								"referenceName": "intpchOrders",
								"type": "DatasetReference"
							},
							"name": "Orders"
						},
						{
							"dataset": {
								"referenceName": "intpchlineitem",
								"type": "DatasetReference"
							},
							"name": "LineItem"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "outdailyCorders",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "join2"
						},
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          C_CUSTKEY as decimal(9,0),",
						"          C_NAME as string,",
						"          C_ADDRESS as string,",
						"          C_NATIONKEY as decimal(38,0),",
						"          C_PHONE as string,",
						"          C_ACCTBAL as decimal(9,2),",
						"          C_MKTSEGMENT as string,",
						"          C_COMMENT as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     format: 'parquet') ~> Customer",
						"source(output(",
						"          O_ORDERKEY as decimal(18,0),",
						"          O_CUSTKEY as decimal(9,0),",
						"          O_ORDERSTATUS as string,",
						"          O_TOTALPRICE as decimal(9,2),",
						"          O_ORDERDATE as date,",
						"          O_ORDERPRIORITY as string,",
						"          O_CLERK as string,",
						"          O_SHIPPRIORITY as decimal(38,0),",
						"          O_COMMENT as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     format: 'parquet') ~> Orders",
						"source(output(",
						"          L_ORDERKEY as decimal(18,0),",
						"          L_PARTKEY as decimal(9,0),",
						"          L_SUPPKEY as decimal(9,0),",
						"          L_LINENUMBER as decimal(38,0),",
						"          L_QUANTITY as decimal(4,2),",
						"          L_EXTENDEDPRICE as decimal(9,2),",
						"          L_DISCOUNT as decimal(12,2),",
						"          L_TAX as decimal(12,2),",
						"          L_RETURNFLAG as string,",
						"          L_LINESTATUS as string,",
						"          L_SHIPDATE as date,",
						"          L_COMMITDATE as date,",
						"          L_RECEIPTDATE as date,",
						"          L_SHIPINSTRUCT as string,",
						"          L_SHIPMODE as string,",
						"          L_COMMENT as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     format: 'parquet') ~> LineItem",
						"Orders, LineItem join(O_ORDERKEY == L_ORDERKEY,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 derive(year = year(O_ORDERDATE),",
						"          month = month(O_ORDERDATE),",
						"          day = dayOfMonth(O_ORDERDATE)) ~> derivedColumn1",
						"derivedColumn1, Customer join(O_CUSTKEY == C_CUSTKEY,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join2",
						"join2 aggregate(groupBy(year,",
						"          month,",
						"          day,",
						"          C_CUSTKEY),",
						"     Tprice = sum(O_TOTALPRICE),",
						"          Tdicount = sum(L_DISCOUNT),",
						"          Tqty = sum(L_QUANTITY),",
						"          Ttax = sum(L_TAX),",
						"          Titem = count(L_LINENUMBER),",
						"          Textprice = sum(L_EXTENDEDPRICE)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'parquet',",
						"     truncate: true,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          year,",
						"          month,",
						"          day,",
						"          C_CUSTKEY,",
						"          Tprice,",
						"          Tdicount,",
						"          Tqty,",
						"          Ttax,",
						"          Titem,",
						"          Textprice",
						"     ),",
						"     partitionBy('key',",
						"          0,",
						"          year,",
						"          month",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/intpchcust')]",
				"[concat(variables('workspaceId'), '/datasets/intpchOrders')]",
				"[concat(variables('workspaceId'), '/datasets/intpchlineitem')]",
				"[concat(variables('workspaceId'), '/datasets/outdailyCorders')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/bbfpdopvconf')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "create database datagovdb;\n\nuse datagovdb;\nCREATE LOGIN [bbfpdopv] FROM EXTERNAL PROVIDER;\n\nuse datagovdb;\nCREATE USER [bbfpdopv] FOR LOGIN [bbfpdopv];\nALTER ROLE db_datareader ADD MEMBER [bbfpdopv];\n\nGRANT REFERENCES ON DATABASE SCOPED CREDENTIAL::[scoped_credential] TO [bbfpdopv];",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "datagovdb",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchoutputdisplay')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpchoutput/**',\n        FORMAT = 'PARQUET'\n    ) \nWITH\n(\n    [day] INT ,\n    [C_CUSTKEY] DECIMAL(9, 0),\n    [Tprice] DECIMAL(10,2),\n    [Tdicount] DECIMAL(10,2),\n    [Tqty] DECIMAL(14, 2),\n    [Ttax] DECIMAL(10,2),\n    [Titem] INT,\n    [Textprice] DECIMAL(19, 2)\n) AS [result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpschexttablecreation')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseParquetFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseParquetFormat] \n\tWITH ( FORMAT_TYPE = PARQUET)\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'root_synpasedlstore_dfs_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [root_synpasedlstore_dfs_core_windows_net] \n\tWITH (\n\t\tLOCATION = 'abfss://root@synpasedlstore.dfs.core.windows.net' \n\t)\nGO\n\nCREATE EXTERNAL TABLE Nation (\n\t[N_NATIONKEY] numeric(38,0),\n\t[N_NAME] nvarchar(4000),\n\t[N_REGIONKEY] numeric(38,0),\n\t[N_COMMENT] nvarchar(4000)\n\t)\n\tWITH (\n\tLOCATION = 'tpch/NATION/**',\n\tDATA_SOURCE = [root_synpasedlstore_dfs_core_windows_net],\n\tFILE_FORMAT = [SynapseParquetFormat]\n\t)\nGO\n\n\nSELECT TOP 100 * FROM dbo.Nation\nGO\n\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpch/PART/**',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n\n\nIF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseParquetFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseParquetFormat] \n\tWITH ( FORMAT_TYPE = PARQUET)\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'root_synpasedlstore_dfs_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [root_synpasedlstore_dfs_core_windows_net] \n\tWITH (\n\t\tLOCATION = 'abfss://root@synpasedlstore.dfs.core.windows.net' \n\t)\nGO\n\nCREATE EXTERNAL TABLE customer (\n\t[C_CUSTKEY] numeric(9,0),\n\t[C_NAME] nvarchar(4000),\n\t[C_ADDRESS] nvarchar(4000),\n\t[C_NATIONKEY] numeric(38,0),\n\t[C_PHONE] nvarchar(4000),\n\t[C_ACCTBAL] numeric(9,2),\n\t[C_MKTSEGMENT] nvarchar(4000),\n\t[C_COMMENT] nvarchar(4000)\n\t)\n\tWITH (\n\tLOCATION = 'tpch/CUSTOMER/**',\n\tDATA_SOURCE = [root_synpasedlstore_dfs_core_windows_net],\n\tFILE_FORMAT = [SynapseParquetFormat]\n\t)\nGO\n\n\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpch/PART/**',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpch/ORDERS/**',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n\nCreate View PartView as (\nSELECT  * FROM\nOPENROWSET( BULK N'https://synpasedlstore.dfs.core.windows.net/root/tpch/PART/**', FORMAT = 'PARQUET') \nWITH (\n      P_PARTKEY DECIMAL(12,0), \n      P_NAME varchar(MAX),\n      P_MFGR varchar(max),\n\t  P_BRAND varchar(1000),\n\t  P_TYPE varchar(100),\n\t  P_CONTAINER varchar(50),\n\t  P_RETAILPRICE numeric(9,0),\n\t  P_COMMENT varchar(max)\n) as rows\n)\n\nSelect top 100 * from PartView\n\nCreate View NationView as (\nSELECT  * FROM\nOPENROWSET( BULK N'https://synpasedlstore.dfs.core.windows.net/root/tpch/NATION/**', FORMAT = 'PARQUET') \nWITH (\n    [N_NATIONKEY] numeric(38,0),\n\t[N_NAME] nvarchar(4000),\n\t[N_REGIONKEY] numeric(38,0),\n\t[N_COMMENT] nvarchar(4000)\n) as rows\n)\n\nCreate View CustomerView as (\nSELECT  * FROM\nOPENROWSET( BULK N'https://synpasedlstore.dfs.core.windows.net/root/tpch/CUSTOMER/**', FORMAT = 'PARQUET') \nWITH (\n\t[C_CUSTKEY] numeric(9,0),\n\t[C_NAME] nvarchar(4000),\n\t[C_ADDRESS] nvarchar(4000),\n\t[C_NATIONKEY] numeric(38,0),\n\t[C_PHONE] nvarchar(4000),\n\t[C_ACCTBAL] numeric(9,2),\n\t[C_MKTSEGMENT] nvarchar(4000),\n\t[C_COMMENT] nvarchar(4000)\n) as rows\n)\n\nCreate View OrderView as (\nSELECT  * FROM\nOPENROWSET( BULK N'https://synpasedlstore.dfs.core.windows.net/root/tpch/ORDERS/**', FORMAT = 'PARQUET') \nWITH (\n\t[O_ORDERKEY] decimal(12,0),\n\t[O_CUSTKEY] decimal(12,0),\n\t[O_ORDERSTATUS] nvarchar(100),\n\t[O_TOTALPRICE] numeric(38,0),\n\t[O_ORDERDATE] DATE,\n\t[O_ORDERPRIORITY] varchar(200),\n\t[O_CLERK] nvarchar(100),\n\t[O_SHIPPRIORITY] decimal(38,0),\n\t[O_COMMENT] varchar(max)\n) as rows\n)\n\n\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpch/LINEITEM/**',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n\nCreate View LineitemView as (\nSELECT * FROM\nOPENROWSET( BULK N'https://synpasedlstore.dfs.core.windows.net/root/tpch/LINEITEM/**', FORMAT = 'PARQUET') \nWITH (\n\t[L_ORDERKEY] decimal(12,0),\n\t[L_PARTKEY] decimal(12,0),\n\t[L_SUPPKEY] decimal(12,0),\n\t[L_LINENUMBER] decimal(12,0),\n\t[L_QUANTITY] decimal(12,0),\n\t[L_EXTENDEDPRICE] numeric(38,0),\n\t[L_DISCOUNT] numeric(38,0),\n\t[L_TAX] numeric(38,0),\n\t[L_RETURNFLAG] varchar(200),\n\t[L_LINESTATUS] varchar(200),\n\t[L_COMMITDATE] DATE,\n\t[L_RECEIPTDATE] DATE,\n\t[L_SHIPINSTRUCT] varchar(max),\n\t[L_SHIPMODE] varchar(max)\n) as rows\n)\n\n\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpch/PARTSUPP/**',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n\ndrop view PartSuppView;\nCreate View PartSuppView as (\nSELECT * FROM\nOPENROWSET( BULK N'https://synpasedlstore.dfs.core.windows.net/root/tpch/PARTSUPP/**', FORMAT = 'PARQUET') \nWITH (\n    [PS_PARTKEY] decimal(38,0),\n\t[PS_SUPPKEY] decimal(38,0),\n\t[PS_AVAILQTY] decimal(38,0),\n\t[PS_SUPPLYCOST] decimal(38,4),\n\t[PS_COMMENT] nvarchar(4000)\n) as rows\n)\n\nCreate View RegionView as (\nSELECT\n    *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpch/REGION/**',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n)\n\nCreate View SupplierView as (\nSELECT\n    *\nFROM\n    OPENROWSET(\n        BULK 'https://synpasedlstore.dfs.core.windows.net/root/tpch/SUPPLIER/**',\n        FORMAT = 'PARQUET'\n    ) AS [result]\n)\n\nselect Top 100 * from SupplierView\n\n\nSelect top 100 * from OrderView a join LineitemView b on a.O_ORDERKEY = L_ORDERKEY\njoin CustomerView c on a.O_CUSTKEY =\n\nselect top 100 * from LineitemView\n\nselect top 100 * from CustomerView\n\nselect top 100 * from NationView\n\nselect top 100 * from OrderView\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "datagovdb",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Data Exploration and ML Modeling - NYC taxi predict using Spark MLlib')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b77c1cb1-2d1f-447f-9d72-c1dd243678e2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# Predict NYC Taxi Tips using Spark ML and Azure Open Datasets\n",
							"\n",
							"The notebook ingests, visualizes, prepares and then trains a model based on an Open Dataset that tracks NYC Yellow Taxi trips and various attributes around them.\n",
							"The goal is to predict for a given trip whether there will be a tip or not.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"import matplotlib.pyplot as plt\n",
							"\n",
							"from pyspark.sql.functions import unix_timestamp\n",
							"\n",
							"from pyspark.sql import SparkSession\n",
							"from pyspark.sql.types import *\n",
							"from pyspark.sql.functions import *\n",
							"\n",
							"from pyspark.ml import Pipeline\n",
							"from pyspark.ml import PipelineModel\n",
							"from pyspark.ml.feature import RFormula\n",
							"from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
							"from pyspark.ml.classification import LogisticRegression\n",
							"from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
							"from pyspark.ml.evaluation import BinaryClassificationEvaluator"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Ingest Data¶ \n",
							"\n",
							"Get a sample data of nyc yellow taxi to make it faster/easier to evaluate different approaches to prep for the modelling phase later in the notebook."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Import NYC yellow cab data from Azure Open Datasets\n",
							"from azureml.opendatasets import NycTlcYellow\n",
							"\n",
							"from datetime import datetime\n",
							"from dateutil import parser\n",
							"\n",
							"end_date = parser.parse('2018-05-08 00:00:00')\n",
							"start_date = parser.parse('2018-05-01 00:00:00')\n",
							"\n",
							"nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\n",
							"nyc_tlc_df = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"source": [
							"#To make development easier, faster and less expensive downsample for now\n",
							"sampled_taxi_df = nyc_tlc_df.sample(True, 0.001, seed=1234)"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Exploratory Data Analysis\n",
							"\n",
							"Look at the data and evaluate its suitability for use in a model, do this via some basic charts focussed on tip values and relationships."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"#The charting package needs a Pandas dataframe or numpy array do the conversion\n",
							"sampled_taxi_pd_df = sampled_taxi_df.toPandas()\n",
							"\n",
							"# Look at tips by amount count histogram\n",
							"ax1 = sampled_taxi_pd_df['tipAmount'].plot(kind='hist', bins=25, facecolor='lightblue')\n",
							"ax1.set_title('Tip amount distribution')\n",
							"ax1.set_xlabel('Tip Amount ($)')\n",
							"ax1.set_ylabel('Counts')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# How many passengers tip'd by various amounts\n",
							"ax2 = sampled_taxi_pd_df.boxplot(column=['tipAmount'], by=['passengerCount'])\n",
							"ax2.set_title('Tip amount by Passenger count')\n",
							"ax2.set_xlabel('Passenger count') \n",
							"ax2.set_ylabel('Tip Amount ($)')\n",
							"plt.suptitle('')\n",
							"plt.show()\n",
							"\n",
							"# Look at the relationship between fare and tip amounts\n",
							"ax = sampled_taxi_pd_df.plot(kind='scatter', x= 'fareAmount', y = 'tipAmount', c='blue', alpha = 0.10, s=2.5*(sampled_taxi_pd_df['passengerCount']))\n",
							"ax.set_title('Tip amount by Fare amount')\n",
							"ax.set_xlabel('Fare Amount ($)')\n",
							"ax.set_ylabel('Tip Amount ($)')\n",
							"plt.axis([-2, 80, -2, 20])\n",
							"plt.suptitle('')\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization\n",
							"\n",
							"It's clear from the visualizations above that there are a bunch of outliers in the data. These will need to be filtered out in addition there are extra variables that are not going to be useful in the model we build at the end.\n",
							"\n",
							"Finally there is a need to create some new (derived) variables that will work better with the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_df = sampled_taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'rateCodeId', 'passengerCount'\\\n",
							"                                , 'tripDistance', 'tpepPickupDateTime', 'tpepDropoffDateTime'\\\n",
							"                                , date_format('tpepPickupDateTime', 'hh').alias('pickupHour')\\\n",
							"                                , date_format('tpepPickupDateTime', 'EEEE').alias('weekdayString')\\\n",
							"                                , (unix_timestamp(col('tpepDropoffDateTime')) - unix_timestamp(col('tpepPickupDateTime'))).alias('tripTimeSecs')\\\n",
							"                                , (when(col('tipAmount') > 0, 1).otherwise(0)).alias('tipped')\n",
							"                                )\\\n",
							"                        .filter((sampled_taxi_df.passengerCount > 0) & (sampled_taxi_df.passengerCount < 8)\\\n",
							"                                & (sampled_taxi_df.tipAmount >= 0) & (sampled_taxi_df.tipAmount <= 25)\\\n",
							"                                & (sampled_taxi_df.fareAmount >= 1) & (sampled_taxi_df.fareAmount <= 250)\\\n",
							"                                & (sampled_taxi_df.tipAmount < sampled_taxi_df.fareAmount)\\\n",
							"                                & (sampled_taxi_df.tripDistance > 0) & (sampled_taxi_df.tripDistance <= 100)\\\n",
							"                                & (sampled_taxi_df.rateCodeId <= 5)\n",
							"                                & (sampled_taxi_df.paymentType.isin({\"1\", \"2\"}))\n",
							"                                )"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data Prep and Featurization Part 2\n",
							"\n",
							"Having created new variables its now possible to drop the columns they were derived from so that the dataframe that goes into the model is the smallest in terms of number of variables, that is required.\n",
							"\n",
							"Also create some more features based on new columns from the first round.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"taxi_featurised_df = taxi_df.select('totalAmount', 'fareAmount', 'tipAmount', 'paymentType', 'passengerCount'\\\n",
							"                                                , 'tripDistance', 'weekdayString', 'pickupHour','tripTimeSecs','tipped'\\\n",
							"                                                , when((taxi_df.pickupHour <= 6) | (taxi_df.pickupHour >= 20),\"Night\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 7) & (taxi_df.pickupHour <= 10), \"AMRush\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 11) & (taxi_df.pickupHour <= 15), \"Afternoon\")\\\n",
							"                                                .when((taxi_df.pickupHour >= 16) & (taxi_df.pickupHour <= 19), \"PMRush\")\\\n",
							"                                                .otherwise(0).alias('trafficTimeBins')\n",
							"                                              )\\\n",
							"                                       .filter((taxi_df.tripTimeSecs >= 30) & (taxi_df.tripTimeSecs <= 7200))"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Encoding\n",
							"\n",
							"Different ML algorithms support different types of input, for this example Logistic Regression is being used for Binary Classification. This means that any Categorical (string) variables must be converted to numbers.\n",
							"\n",
							"The process is not as simple as a \"map\" style function as the relationship between the numbers can introduce a bias in the resulting model, the approach is to index the variable and then encode using a std approach called One Hot Encoding.\n",
							"\n",
							"This approach requires the encoder to \"learn\"/fit a model over the data in the Spark instance and then transform based on what was learnt.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# The sample uses an algorithm that only works with numeric features convert them so they can be consumed\n",
							"sI1 = StringIndexer(inputCol=\"trafficTimeBins\", outputCol=\"trafficTimeBinsIndex\"); \n",
							"en1 = OneHotEncoder(dropLast=False, inputCol=\"trafficTimeBinsIndex\", outputCol=\"trafficTimeBinsVec\");\n",
							"sI2 = StringIndexer(inputCol=\"weekdayString\", outputCol=\"weekdayIndex\"); \n",
							"en2 = OneHotEncoder(dropLast=False, inputCol=\"weekdayIndex\", outputCol=\"weekdayVec\");\n",
							"\n",
							"# Create a new dataframe that has had the encodings applied\n",
							"encoded_final_df = Pipeline(stages=[sI1, en1, sI2, en2]).fit(taxi_featurised_df).transform(taxi_featurised_df)"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Generation of Testing and Training Data Sets\n",
							"Simple split, 70% for training and 30% for testing the model. Playing with this ratio may result in different models.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Decide on the split between training and testing data from the dataframe \n",
							"trainingFraction = 0.7\n",
							"testingFraction = (1-trainingFraction)\n",
							"seed = 1234\n",
							"\n",
							"# Split the dataframe into test and training dataframes\n",
							"train_data_df, test_data_df = encoded_final_df.randomSplit([trainingFraction, testingFraction], seed=seed)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Train the Model\n",
							"\n",
							"Train the Logistic Regression model and then evaluate it using Area under ROC as the metric."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Create a new LR object for the model\n",
							"logReg = LogisticRegression(maxIter=10, regParam=0.3, labelCol = 'tipped')\n",
							"\n",
							"## The formula for the model\n",
							"classFormula = RFormula(formula=\"tipped ~ pickupHour + weekdayVec + passengerCount + tripTimeSecs + tripDistance + fareAmount + paymentType+ trafficTimeBinsVec\")\n",
							"\n",
							"## Undertake training and create an LR model\n",
							"lrModel = Pipeline(stages=[classFormula, logReg]).fit(train_data_df)\n",
							"\n",
							"## Saving the model is optional but its another for of inter session cache\n",
							"datestamp = datetime.now().strftime('%m-%d-%Y-%s');\n",
							"fileName = \"lrModel_\" + datestamp;\n",
							"logRegDirfilename = fileName;\n",
							"lrModel.save(logRegDirfilename)\n",
							"\n",
							"## Predict tip 1/0 (yes/no) on the test dataset, evaluation using AUROC\n",
							"predictions = lrModel.transform(test_data_df)\n",
							"predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
							"metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
							"print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Evaluate and Visualize\n",
							"\n",
							"Plot the actual curve to develop a better understanding of the model.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"## Plot the ROC curve, no need for pandas as this uses the modelSummary object\n",
							"modelSummary = lrModel.stages[-1].summary\n",
							"\n",
							"plt.plot([0, 1], [0, 1], 'r--')\n",
							"plt.plot(modelSummary.roc.select('FPR').collect(),\n",
							"         modelSummary.roc.select('TPR').collect())\n",
							"plt.xlabel('False Positive Rate')\n",
							"plt.ylabel('True Positive Rate')\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 10
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Using Azure Open Datasets in Synapse')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "75454d26-2887-4e18-945c-f019ef203ed3"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# Using Azure Open Datasets in Synapse - Enrich NYC Green Taxi Data with Holiday and Weather\n",
							"\n",
							"Synapse has [Azure Open Datasets](https://azure.microsoft.com/en-us/services/open-datasets/) package pre-installed. This notebook provides examples of how to enrich NYC Green Taxi Data with Holiday and Weather with focusing on :\n",
							"- read Azure Open Dataset\n",
							"- manipulate the data to prepare for further analysis, including column projection, filtering, grouping and joins etc. \n",
							"- create a Spark table to be used in other notebooks for modeling training"
						]
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Data loading \n",
							"Let's first load the [NYC green taxi trip records](https://azure.microsoft.com/en-us/services/open-datasets/catalog/nyc-taxi-limousine-commission-green-taxi-trip-records/). The Open Datasets package contains a class representing each data source (NycTlcGreen for example) to easily filter date parameters before downloading."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from azureml.opendatasets import NycTlcGreen\n",
							"\n",
							"from datetime import datetime\n",
							"from dateutil import parser\n",
							"end_date = parser.parse('2018-06-06')\n",
							"start_date = parser.parse('2018-05-01')\n",
							"\n",
							"nyc_tlc = NycTlcGreen(start_date=start_date, end_date=end_date)\n",
							"nyc_tlc_df = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"# Display 5 rows\n",
							"\n",
							"nyc_tlc_df.show(5, truncate = False)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"source": [
							"Now that the initial data is loaded. Let's do some projection on the data to \n",
							"- create new columns for the month number, day of month, day of week, and hour of day. These info is going to be used in the training model to factor in time-based seasonality.\n",
							"- add a static feature for the country code to join holiday data. "
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Extract month, day of month, and day of week from pickup datetime and add a static column for the country code to join holiday data. \n",
							"\n",
							"import pyspark.sql.functions as f\n",
							"\n",
							"nyc_tlc_df_expand = nyc_tlc_df.withColumn('datetime',f.to_date('lpepPickupDatetime'))\\\n",
							"                .withColumn('month_num',f.month(nyc_tlc_df.lpepPickupDatetime))\\\n",
							"                .withColumn('day_of_month',f.dayofmonth(nyc_tlc_df.lpepPickupDatetime))\\\n",
							"                .withColumn('day_of_week',f.dayofweek(nyc_tlc_df.lpepPickupDatetime))\\\n",
							"                .withColumn('hour_of_day',f.hour(nyc_tlc_df.lpepPickupDatetime))\\\n",
							"                .withColumn('country_code',f.lit('US'))"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "markdown",
						"source": [
							"Remove some of the columns that won't need for modeling or additional feature building.\n",
							"\n",
							"\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Remove unused columns from nyc green taxi data\n",
							"\n",
							"columns_to_remove = [\"lpepDropoffDatetime\", \"puLocationId\", \"doLocationId\", \"pickupLongitude\", \n",
							"                     \"pickupLatitude\", \"dropoffLongitude\",\"dropoffLatitude\" ,\"rateCodeID\", \n",
							"                     \"storeAndFwdFlag\",\"paymentType\", \"fareAmount\", \"extra\", \"mtaTax\",\n",
							"                     \"improvementSurcharge\", \"tollsAmount\", \"ehailFee\", \"tripType \"  \n",
							"                    ]\n",
							"\n",
							"nyc_tlc_df_clean = nyc_tlc_df_expand.select([column for column in nyc_tlc_df_expand.columns if column not in columns_to_remove])"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							"# Display 5 rows\n",
							"nyc_tlc_df_clean.show(5)"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Enrich with holiday data\n",
							"Now that we have taxi data downloaded and roughly prepared, add in holiday data as additional features. Holiday-specific features will assist model accuracy, as major holidays are times where taxi demand increases dramatically and supply becomes limited. \n",
							"\n",
							"Let's load the [public holidays](https://azure.microsoft.com/en-us/services/open-datasets/catalog/public-holidays/) from Azure Open datasets.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from azureml.opendatasets import PublicHolidays\n",
							"\n",
							"hol = PublicHolidays(start_date=start_date, end_date=end_date)\n",
							"hol_df = hol.to_spark_dataframe()\n",
							"\n",
							"# Display data\n",
							"hol_df.show(5, truncate = False)"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"source": [
							"Rename the countryRegionCode and date columns to match the respective field names from the taxi data, and also normalize the time so it can be used as a key. "
						]
					},
					{
						"cell_type": "code",
						"source": [
							"hol_df_clean = hol_df.withColumnRenamed('countryRegionCode','country_code')\\\n",
							"            .withColumn('datetime',f.to_date('date'))\n",
							"\n",
							"hol_df_clean.show(5)"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"source": [
							"Next, join the holiday data with the taxi data by performing a left-join. This will preserve all records from taxi data, but add in holiday data where it exists for the corresponding datetime and country_code, which in this case is always \"US\". Preview the data to verify that they were merged correctly."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# enrich taxi data with holiday data\n",
							"nyc_taxi_holiday_df = nyc_tlc_df_clean.join(hol_df_clean, on = ['datetime', 'country_code'] , how = 'left')\n",
							"\n",
							"nyc_taxi_holiday_df.show(5)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"source": [
							"# Create a temp table and filter out non empty holiday rows\n",
							"\n",
							"nyc_taxi_holiday_df.createOrReplaceTempView(\"nyc_taxi_holiday_df\")\n",
							"spark.sql(\"SELECT * from nyc_taxi_holiday_df WHERE holidayName is NOT NULL \").show(5, truncate = False)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Enrich with weather data¶\n",
							"\n",
							"Now we append NOAA surface weather data to the taxi and holiday data. Use a similar approach to fetch the [NOAA weather history data](https://azure.microsoft.com/en-us/services/open-datasets/catalog/noaa-integrated-surface-data/) from Azure Open Datasets. "
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from azureml.opendatasets import NoaaIsdWeather\n",
							"\n",
							"isd = NoaaIsdWeather(start_date, end_date)\n",
							"isd_df = isd.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"source": [
							"isd_df.show(5, truncate = False)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"source": [
							"# Filter out weather info for new york city, remove the recording with null temperature \n",
							"\n",
							"weather_df = isd_df.filter(isd_df.latitude >= '40.53')\\\n",
							"                        .filter(isd_df.latitude <= '40.88')\\\n",
							"                        .filter(isd_df.longitude >= '-74.09')\\\n",
							"                        .filter(isd_df.longitude <= '-73.72')\\\n",
							"                        .filter(isd_df.temperature.isNotNull())\\\n",
							"                        .withColumnRenamed('datetime','datetime_full')\n",
							"                         "
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"source": [
							"# Remove unused columns\n",
							"\n",
							"columns_to_remove_weather = [\"usaf\", \"wban\", \"longitude\", \"latitude\"]\n",
							"weather_df_clean = weather_df.select([column for column in weather_df.columns if column not in columns_to_remove_weather])\\\n",
							"                        .withColumn('datetime',f.to_date('datetime_full'))\n",
							"\n",
							"weather_df_clean.show(5, truncate = False)"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"source": [
							"Next group the weather data so that you have daily aggregated weather values. \n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Enrich weather data with aggregation statistics\n",
							"\n",
							"aggregations = {\"snowDepth\": \"mean\", \"precipTime\": \"max\", \"temperature\": \"mean\", \"precipDepth\": \"max\"}\n",
							"weather_df_grouped = weather_df_clean.groupby(\"datetime\").agg(aggregations)"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"source": [
							"weather_df_grouped.show(5)"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"source": [
							"# Rename columns\n",
							"\n",
							"weather_df_grouped = weather_df_grouped.withColumnRenamed('avg(snowDepth)','avg_snowDepth')\\\n",
							"                                       .withColumnRenamed('avg(temperature)','avg_temperature')\\\n",
							"                                       .withColumnRenamed('max(precipTime)','max_precipTime')\\\n",
							"                                       .withColumnRenamed('max(precipDepth)','max_precipDepth')"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "markdown",
						"source": [
							"Merge the taxi and holiday data you prepared with the new weather data. This time you only need the datetime key, and again perform a left-join of the data. Run the describe() function on the new dataframe to see summary statistics for each field."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# enrich taxi data with weather\n",
							"nyc_taxi_holiday_weather_df = nyc_taxi_holiday_df.join(weather_df_grouped, on = 'datetime' , how = 'left')\n",
							"nyc_taxi_holiday_weather_df.cache()"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"source": [
							"nyc_taxi_holiday_weather_df.show(5)"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"collapsed": false
						},
						"source": [
							"# Run the describe() function on the new dataframe to see summary statistics for each field.\n",
							"\n",
							"display(nyc_taxi_holiday_weather_df.describe())"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "markdown",
						"source": [
							"The summary statistics shows that the totalAmount field has negative values, which don't make sense in the context.\n",
							"\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Remove invalid rows with less than 0 taxi fare or tip\n",
							"final_df = nyc_taxi_holiday_weather_df.filter(nyc_taxi_holiday_weather_df.tipAmount > 0)\\\n",
							"                                      .filter(nyc_taxi_holiday_weather_df.totalAmount > 0)"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Cleaning up the existing Database\n",
							"\n",
							"First we need to drop the tables since Spark requires that a database is empty before we can drop the Database.\n",
							"\n",
							"Then we recreate the database and set the default database context to it."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"spark.sql(\"DROP TABLE IF EXISTS NYCTaxi.nyc_taxi_holiday_weather\"); "
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"source": [
							"spark.sql(\"DROP DATABASE IF EXISTS NYCTaxi\"); \n",
							"spark.sql(\"CREATE DATABASE NYCTaxi\"); \n",
							"spark.sql(\"USE NYCTaxi\");"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Creating a new table\n",
							"We create a nyc_taxi_holiday_weather table from the nyc_taxi_holiday_weather dataframe.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession\n",
							"from pyspark.sql.types import *\n",
							"\n",
							"final_df.write.saveAsTable(\"nyc_taxi_holiday_weather\");\n",
							"spark.sql(\"SELECT COUNT(*) FROM nyc_taxi_holiday_weather\").show();"
						],
						"outputs": [],
						"execution_count": 23
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/downloadtpch')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "50a2217f-f7ac-4eb2-9ca6-d488647717bf"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"pip install wget"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import wget\r\n",
							"url = 'https://drive.google.com/file/d/14fyJnKFkCPcQw1q9dG0BE1t7RNNmYP8C/view?usp=sharing'\r\n",
							"#filename = wget.download(url)\r\n",
							"\r\n",
							"output_directory = 'tpch'\r\n",
							"filename = wget.download(url, out=output_directory)"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from notebookutils import mssparkutils\r\n",
							"mssparkutils.fs.ls('/')"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/fhvnoaadatasave')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "0e7ad72d-c1cb-4ee6-9b05-0e8d113496e1"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\n",
							"blob_account_name = \"azureopendatastorage\"\n",
							"blob_container_name = \"nyctlc\"\n",
							"blob_relative_path = \"fhv\"\n",
							"blob_sas_token = r\"\"\n",
							"# Allow SPARK to read from Blob remotely\n",
							"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
							"\n",
							"spark.conf.set(\n",
							"    'fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),\n",
							"    blob_sas_token)\n",
							"df = spark.read.parquet(wasbs_path)\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.count()"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.repartition(5).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/nycfhv/')"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from azureml.opendatasets import NoaaIsdWeather\r\n",
							"\r\n",
							"data = NoaaIsdWeather()\r\n",
							"#df1 = data.to_spark_dataframe()\r\n",
							"# Display 10 rows\r\n",
							"#display(df1.limit(10))\r\n",
							"# no data "
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df1.count()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.repartition(1).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/noaa/')"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/gnoemics1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 3,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "3",
						"spark.dynamicAllocation.maxExecutors": "3",
						"spark.autotune.trackingId": "f74b81ab-5a24-46b6-b3de-c14c04014749"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"pip install glow"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import explode, col, lit, xxhash64\r\n",
							"from math import ceil\r\n",
							"\r\n",
							"# Import glow.py and register Glow package\r\n",
							"import glow\r\n",
							"glow.register(spark)"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#https://github.com/microsoft/genomicsnotebook/blob/main/vcf2parquet-conversion/1000genomes/vcf2parquet-1000genomes.ipynb"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Provide your storage account, container and SAS token\r\n",
							"outputStorageAccount = \"synpasedlstore\"\r\n",
							"outputContainer = \"gnenome\"\r\n",
							"outputSAS = \"sp=r&st=2023-01-10T21:08:19Z&se=2023-02-01T05:08:19Z&spr=https&sv=2021-06-08&sr=c&sig=abZitK3pzUimFU2NxMEK5U82PeYSV6NyX6r84CZkLN0%3D\"\r\n",
							"outputDir = \"data\"\r\n",
							"outputSASURL = \"https://synpasedlstore.blob.core.windows.net/gnenome?sp=r&st=2023-01-10T21:08:19Z&se=2023-02-01T05:08:19Z&spr=https&sv=2021-06-08&sr=c&sig=abZitK3pzUimFU2NxMEK5U82PeYSV6NyX6r84CZkLN0%3D\""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Configure session credentials\r\n",
							"# Set up a SAS for a container with public data - no changes needed here (public SAS)\r\n",
							"spark.conf.set(\r\n",
							"  \"fs.azure.sas.dataset.dataset1000genomes.blob.core.windows.net\",\r\n",
							"  \"sv=2019-10-10&si=prod&sr=c&sig=9nzcxaQn0NprMPlSh4RhFQHcXedLQIcFgbERiooHEqM%3D\")\r\n",
							"\r\n",
							"# Set up a SAS for a container to store .parquet files\r\n",
							"spark.conf.set(\r\n",
							"  \"fs.azure.sas.\"+outputContainer+\".\"+outputStorageAccount+\".blob.core.windows.net\", outputSAS)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# DropDuplicates() partitions into 200 pieces (default value)\r\n",
							"# To change default number of partitions change config -  sqlContext.setConf(\"spark.sql.shuffle.partitions\", )\r\n",
							"partitionMax = 1500\r\n",
							"sqlContext.setConf(\"spark.sql.shuffle.partitions\", partitionMax)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Flatten struct columns\r\n",
							"def flattenStructFields(df):\r\n",
							"  flat_cols = [c[0] for c in df.dtypes if c[1][:6] != 'struct']\r\n",
							"  nested_cols = [c[0] for c in df.dtypes if c[1][:6] =='struct']\r\n",
							"  flat_df = df.select(flat_cols + \r\n",
							"                     [col(nc+'.'+c).alias(nc+'_'+c)\r\n",
							"                     for nc in nested_cols\r\n",
							"                     for c in df.select(nc+'.*').columns])\r\n",
							"  return flat_df\r\n",
							"\r\n",
							"# Add empty columns to match schema\r\n",
							"def completeSchema(df, diffSet):\r\n",
							"  full_df = df\r\n",
							"  for column in diffSet:\r\n",
							"    full_df = full_df.withColumn(column.name, lit(None).cast(column.dataType.simpleString()))\r\n",
							"  return full_df\r\n",
							"\r\n",
							"# Transform dataframe with original vcf schema\r\n",
							"def transformVcf(df, toFlatten, toHash, fullSchemaFields):\r\n",
							"  # Drop duplicates\r\n",
							"  dataDedup = df.dropDuplicates()\r\n",
							"     \r\n",
							"  # Add hashId column to identify variants\r\n",
							"  if toHash:\r\n",
							"    hashCols = list(set(data.columns) - {'genotypes'})\r\n",
							"    dataHashed = dataDedup.withColumn('hashId', xxhash64(*hashCols))\r\n",
							"  else:\r\n",
							"    dataHashed = dataDedup\r\n",
							"  \r\n",
							"  # Flatten data - explode on genotypes, create separate column for each genotypes field, add empty columns to match schema to full dataset\r\n",
							"  if not toFlatten:\r\n",
							"    dataFinal = dataHashed\r\n",
							"  else:\r\n",
							"  # Explode and flatten data\r\n",
							"    dataExploded = dataHashed.withColumn('genotypes', explode('genotypes'))\r\n",
							"    dataExplodedFlatten = flattenStructFields(dataExploded)\r\n",
							"  # Find schema for contig dataset and add columns to match full schema\r\n",
							"    contigSet = set(dataExplodedFlatten.schema.fields)\r\n",
							"    diffSet =(fullSchemaFields - contigSet)\r\n",
							"    dataFinal = completeSchema(dataExplodedFlatten, diffSet)\r\n",
							"   \r\n",
							"  return dataFinal"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Create widgets for toFlatten and contigs\r\n",
							"flatOptions = [False, True]\r\n",
							"dbutils.widgets.dropdown(\"flatten\", \"False\", [str(x) for x in flatOptions])\r\n",
							"\r\n",
							"contigOptions =  list(map(str, range(1, 23)))\r\n",
							"contigLiterals = ['X','Y','MT', 'All']\r\n",
							"contigOptions.extend(contigLiterals)\r\n",
							"dbutils.widgets.multiselect(\"contigsToProcess\", \"22\", contigOptions)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Define parameters\r\n",
							"toFlatten = eval(getArgument(\"flatten\"))\r\n",
							"toHash = True\r\n",
							"repartitionCoef = 45 / 1000000 # gives ~20MB .parquet files\r\n",
							"\r\n",
							"# Define contig list\r\n",
							"contigs = getArgument(\"contigsToProcess\").split(\",\")\r\n",
							"if \"All\" in contigs:\r\n",
							"  contigs = contigOptions\r\n",
							"  contigs.remove('All')\r\n",
							"\r\n",
							"# Find schema for full dataset\r\n",
							"sourceAll = \"wasbs://dataset@dataset1000genomes.blob.core.windows.net/release/20130502/ALL.chr*.vcf.gz\"\r\n",
							"dataAll = spark.read\\\r\n",
							"  .format(\"vcf\")\\\r\n",
							"  .option(\"includeSampleIds\", True)\\\r\n",
							"  .option(\"flattenInfoFields\", True)\\\r\n",
							"  .load(sourceAll)\r\n",
							"\r\n",
							"dataAllExploded = dataAll.withColumn('genotypes', explode('genotypes'))\r\n",
							"dataAllExplodedFlatten = flattenStructFields(dataAllExploded)\r\n",
							"fullSet = set(dataAllExplodedFlatten.schema.fields)\r\n",
							"                 \r\n",
							"for contig in contigs:\r\n",
							"  source = \"wasbs://dataset@dataset1000genomes.blob.core.windows.net/release/20130502/ALL.chr\"+contig+\".*.vcf.gz\"\r\n",
							"\r\n",
							"# Load data\r\n",
							"  data = spark.read\\\r\n",
							"    .format(\"vcf\")\\\r\n",
							"    .option(\"includeSampleIds\", True)\\\r\n",
							"    .option(\"flattenInfoFields\", True)\\\r\n",
							"    .load(source)\r\n",
							"  \r\n",
							"  # Define number of partitions, will be used for coalesce later\r\n",
							"  rowCount = data.count()\r\n",
							"  partCount = ceil (repartitionCoef * rowCount)  \r\n",
							"  if partCount > partitionMax:\r\n",
							"    partCount = partitionMax\r\n",
							"\r\n",
							"  dataFinal = transformVcf(data, toFlatten, toHash, fullSet)\r\n",
							"  if not toFlatten:\r\n",
							"    sink = \"wasbs://\"+outputContainer + \"@\" + outputStorageAccount + \".blob.core.windows.net\"+ outputDir + \"/original/chr\"+contig\r\n",
							"  else:\r\n",
							"    sink = \"wasbs://\"+outputContainer + \"@\" + outputStorageAccount + \".blob.core.windows.net\"+ outputDir + \"/flattened/chr\"+contig\r\n",
							"                 \r\n",
							"  dataFinal.coalesce(partCount). \\\r\n",
							"    write. \\\r\n",
							"    mode(\"overwrite\"). \\\r\n",
							"    format(\"parquet\"). \\\r\n",
							"    save(sink)"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/multivaritest')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 5,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "5",
						"spark.dynamicAllocation.maxExecutors": "5",
						"spark.autotune.trackingId": "69c8db92-526d-4499-abde-7a112aae557a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#https://microsoft.github.io/SynapseML/docs/features/cognitive_services/CognitiveServices%20-%20Multivariate%20Anomaly%20Detection/"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%%configure -f\r\n",
							"{\r\n",
							"  \"name\": \"synapseml\",\r\n",
							"  \"conf\": {\r\n",
							"      \"spark.jars.packages\": \"com.microsoft.azure:synapseml_2.12:0.10.2\",\r\n",
							"      \"spark.jars.repositories\": \"https://mmlspark.azureedge.net/maven\",\r\n",
							"      \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind\",\r\n",
							"      \"spark.yarn.user.classpath.first\": \"true\"\r\n",
							"  }\r\n",
							"}"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import synapse.ml.core\r\n",
							"\r\n",
							"synapse.ml.core.__spark_package_version__\r\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from synapse.ml.cognitive import *\r\n",
							"from notebookutils import mssparkutils\r\n",
							"import numpy as np\r\n",
							"import pandas as pd\r\n",
							"import pyspark\r\n",
							"from pyspark.sql.functions import col\r\n",
							"from pyspark.sql.functions import lit\r\n",
							"from pyspark.sql.types import DoubleType\r\n",
							"import synapse.ml"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://metricfolder@synpasedlstore.dfs.core.windows.net/sensor.csv', format='csv'\r\n",
							"## If header exists uncomment line below\r\n",
							", header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#!wget https://sparkdemostorage.blob.core.windows.net/mvadcsvdata/spark-demo-data.csv"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#df = spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://mvadcsvdata@sparkdemostorage.blob.core.windows.net/spark-demo-data.csv\")"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#df = spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://metricfolder@synpasedlstore.blob.core.windows.net/train_set.csv\")\r\n",
							"df = df.withColumn(\"sensor_01\", col(\"sensor_01\").cast(DoubleType())) \\\r\n",
							"    .withColumn(\"sensor_02\", col(\"sensor_02\").cast(DoubleType())) \\\r\n",
							"    .withColumn(\"sensor_03\", col(\"sensor_03\").cast(DoubleType()))\r\n",
							"\r\n",
							"df.show(10)"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import os\r\n",
							"from pyspark.sql import SparkSession\r\n",
							"from synapse.ml.core.platform import find_secret\r\n",
							"\r\n",
							"# Bootstrap Spark Session\r\n",
							"spark = SparkSession.builder.getOrCreate()"
						],
						"outputs": [],
						"execution_count": 42
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# An Anomaly Dectector subscription key\r\n",
							"#anomalyKey = find_secret(\"anomaly-api-key\")\r\n",
							"anomalyKey = mssparkutils.credentials.getSecret(\"mlopskeyv1\",\"anomalykey\")\r\n",
							"# Your storage account name\r\n",
							"storageName = \"synpasedlstore\"\r\n",
							"# A connection string to your blob storage account\r\n",
							"#storageKey = find_secret(\"madtest-storage-key\")\r\n",
							"storageKey = \"l86dmmORzfrNQN1LcNosdYFaE1ET+ohUBWfaNXabC3nny5OfJWBDsK0T3HC+gMbSdH5kexDnJhFZ+AStrv675g==\"\r\n",
							"# A place to save intermediate MVAD results\r\n",
							"intermediateSaveDir = (\r\n",
							"    \"wasbs://metricfolder@synpasedlstore.blob.core.windows.net/intermediateData\"\r\n",
							")\r\n",
							"# The location of the anomaly detector resource that you created\r\n",
							"location = \"eastus\""
						],
						"outputs": [],
						"execution_count": 45
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"spark.sparkContext._jsc.hadoopConfiguration().set(\r\n",
							"    f\"fs.azure.account.key.{storageName}.blob.core.windows.net\", storageKey\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 46
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import numpy as np\r\n",
							"import pandas as pd\r\n",
							"\r\n",
							"import pyspark\r\n",
							"from pyspark.sql.functions import col\r\n",
							"from pyspark.sql.functions import lit\r\n",
							"from pyspark.sql.types import DoubleType\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"\r\n",
							"import synapse.ml\r\n",
							"from synapse.ml.cognitive import *"
						],
						"outputs": [],
						"execution_count": 47
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = (\r\n",
							"    spark.read.format(\"csv\")\r\n",
							"    .option(\"header\", \"true\")\r\n",
							"    .load(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/MVAD/sample.csv\")\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 37
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = (\r\n",
							"    df.withColumn(\"sensor_1\", col(\"sensor_1\").cast(DoubleType()))\r\n",
							"    .withColumn(\"sensor_2\", col(\"sensor_2\").cast(DoubleType()))\r\n",
							"    .withColumn(\"sensor_3\", col(\"sensor_3\").cast(DoubleType()))\r\n",
							")\r\n",
							"\r\n",
							"# Let's inspect the dataframe:\r\n",
							"df.show(5)"
						],
						"outputs": [],
						"execution_count": 38
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(df)"
						],
						"outputs": [],
						"execution_count": 39
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"trainingStartTime = \"2020-06-01T12:00:00Z\"\r\n",
							"trainingEndTime = \"2020-07-02T17:55:00Z\"\r\n",
							"timestampColumn = \"timestamp\"\r\n",
							"inputColumns = [\"sensor_1\", \"sensor_2\", \"sensor_3\"]\r\n",
							"\r\n",
							"estimator = (\r\n",
							"    FitMultivariateAnomaly()\r\n",
							"    .setSubscriptionKey(anomalyKey)\r\n",
							"    .setLocation(location)\r\n",
							"    .setStartTime(trainingStartTime)\r\n",
							"    .setEndTime(trainingEndTime)\r\n",
							"    .setIntermediateSaveDir(intermediateSaveDir)\r\n",
							"    .setTimestampCol(timestampColumn)\r\n",
							"    .setInputCols(inputColumns)\r\n",
							"    .setSlidingWindow(200)\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 48
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"model = estimator.fit(df)"
						],
						"outputs": [],
						"execution_count": 49
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"inferenceStartTime = \"2020-07-02T18:00:00Z\"\r\n",
							"inferenceEndTime = \"2020-07-06T05:15:00Z\"\r\n",
							"\r\n",
							"result = (\r\n",
							"    model.setStartTime(inferenceStartTime)\r\n",
							"    .setEndTime(inferenceEndTime)\r\n",
							"    .setOutputCol(\"results\")\r\n",
							"    .setErrorCol(\"errors\")\r\n",
							"    .setInputCols(inputColumns)\r\n",
							"    .setTimestampCol(timestampColumn)\r\n",
							"    .transform(df)\r\n",
							")\r\n",
							"\r\n",
							"result.show(5)"
						],
						"outputs": [],
						"execution_count": 50
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"rdf = (\r\n",
							"    result.select(\r\n",
							"        \"timestamp\",\r\n",
							"        *inputColumns,\r\n",
							"        \"results.contributors\",\r\n",
							"        \"results.isAnomaly\",\r\n",
							"        \"results.severity\"\r\n",
							"    )\r\n",
							"    .orderBy(\"timestamp\", ascending=True)\r\n",
							"    .filter(col(\"timestamp\") >= lit(inferenceStartTime))\r\n",
							"    .toPandas()\r\n",
							")\r\n",
							"\r\n",
							"rdf"
						],
						"outputs": [],
						"execution_count": 51
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def parse(x):\r\n",
							"    if type(x) is list:\r\n",
							"        return dict([item[::-1] for item in x])\r\n",
							"    else:\r\n",
							"        return {\"series_0\": 0, \"series_1\": 0, \"series_2\": 0}\r\n",
							"\r\n",
							"\r\n",
							"rdf[\"contributors\"] = rdf[\"contributors\"].apply(parse)\r\n",
							"rdf = pd.concat(\r\n",
							"    [rdf.drop([\"contributors\"], axis=1), pd.json_normalize(rdf[\"contributors\"])], axis=1\r\n",
							")\r\n",
							"rdf"
						],
						"outputs": [],
						"execution_count": 52
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import synapse.ml.core\r\n",
							"\r\n",
							"synapse.ml.core.__spark_package_version__\r\n",
							""
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from synapse.ml.cognitive import *\r\n",
							"\r\n",
							"anomalyKey = mssparkutils.credentials.getSecret(\"mlopskeyv1\",\"anomalykey\")\r\n",
							"\r\n",
							"from pyspark.sql.functions import lit\r\n",
							"df = spark.createDataFrame([\r\n",
							"    (\"1972-01-01T00:00:00Z\", 826.0),\r\n",
							"    (\"1972-02-01T00:00:00Z\", 799.0),\r\n",
							"    (\"1972-03-01T00:00:00Z\", 890.0),\r\n",
							"    (\"1972-04-01T00:00:00Z\", 900.0),\r\n",
							"    (\"1972-05-01T00:00:00Z\", 766.0),\r\n",
							"    (\"1972-06-01T00:00:00Z\", 805.0),\r\n",
							"    (\"1972-07-01T00:00:00Z\", 821.0),\r\n",
							"    (\"1972-08-01T00:00:00Z\", 20000.0),\r\n",
							"    (\"1972-09-01T00:00:00Z\", 883.0),\r\n",
							"    (\"1972-10-01T00:00:00Z\", 898.0),\r\n",
							"    (\"1972-11-01T00:00:00Z\", 957.0),\r\n",
							"    (\"1972-12-01T00:00:00Z\", 924.0),\r\n",
							"    (\"1973-01-01T00:00:00Z\", 881.0),\r\n",
							"    (\"1973-02-01T00:00:00Z\", 837.0),\r\n",
							"    (\"1973-03-01T00:00:00Z\", 9000.0)\r\n",
							"], [\"timestamp\", \"value\"]).withColumn(\"group\", lit(\"series1\"))\r\n",
							"\r\n",
							"#anomalyDetector = (SimpleDetectAnomalies() \r\n",
							"    #.setLinkedService(\"AnomalyDetector\")\r\n",
							"#    .setSubscriptionKey(anomalyKey)\r\n",
							"#    .setOutputCol(\"output\")\r\n",
							"#    .setErrorCol(\"error\")\r\n",
							"#    .setGranularity(\"monthly\")\r\n",
							"#    .setTimestampCol(\"timestamp\")\r\n",
							"#    .setValueCol(\"value\")\r\n",
							"#    .setGroupbyCol(\"group\"))\r\n",
							"\r\n",
							"sda = (SimpleDetectAnomalies()\r\n",
							"        .setSubscriptionKey(anomalyKey)\r\n",
							"        .setLocation(\"eastus\")\r\n",
							"        .setOutputCol(\"anomalies\")\r\n",
							"        .setGroupbyCol(\"group\")\r\n",
							"        .setTimestampCol(\"timestamp\")\r\n",
							"        .setErrorCol(\"error\")\r\n",
							"        .setGranularity(\"monthly\"))\r\n",
							"\r\n",
							"\r\n",
							"#sda.transform(df).show()\r\n",
							"\r\n",
							"#results = anomalyDetector.transform(df)\r\n",
							"results = sda.transform(df)\r\n",
							"\r\n",
							"# Show the results\r\n",
							"#display(results.select(\"timestamp\", \"value\", \"group\", \"output.*\", \"error\").limit(10))\r\n",
							"#display(results)\r\n",
							"display(results.select(\"timestamp\", \"value\", \"group\", \"anomalies\", \"error\").limit(10))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"minSeverity = 0.1\r\n",
							"\r\n",
							"\r\n",
							"####### Main Figure #######\r\n",
							"plt.figure(figsize=(23, 8))\r\n",
							"plt.plot(\r\n",
							"    rdf[\"timestamp\"],\r\n",
							"    rdf[\"sensor_1\"],\r\n",
							"    color=\"tab:orange\",\r\n",
							"    #line,\r\n",
							"    linewidth=2,\r\n",
							"    label=\"sensor_1\",\r\n",
							")\r\n",
							"plt.plot(\r\n",
							"    rdf[\"timestamp\"],\r\n",
							"    rdf[\"sensor_2\"],\r\n",
							"    color=\"tab:green\",\r\n",
							"    #line,\r\n",
							"    linewidth=2,\r\n",
							"    label=\"sensor_2\",\r\n",
							")\r\n",
							"plt.plot(\r\n",
							"    rdf[\"timestamp\"],\r\n",
							"    rdf[\"sensor_3\"],\r\n",
							"    color=\"tab:blue\",\r\n",
							"    #line,\r\n",
							"    linewidth=2,\r\n",
							"    label=\"sensor_3\",\r\n",
							")\r\n",
							"plt.grid(axis=\"y\")\r\n",
							"plt.tick_params(axis=\"x\", which=\"both\", bottom=False, labelbottom=False)\r\n",
							"plt.legend()\r\n",
							"\r\n",
							"anoms = list(rdf[\"severity\"] >= minSeverity)\r\n",
							"_, _, ymin, ymax = plt.axis()\r\n",
							"plt.vlines(np.where(anoms), ymin=ymin, ymax=ymax, color=\"r\", alpha=0.8)\r\n",
							"\r\n",
							"plt.legend()\r\n",
							"plt.title(\r\n",
							"    \"A plot of the values from the three sensors with the detected anomalies highlighted in red.\"\r\n",
							")\r\n",
							"plt.show()\r\n",
							"\r\n",
							"####### Severity Figure #######\r\n",
							"plt.figure(figsize=(23, 1))\r\n",
							"plt.tick_params(axis=\"x\", which=\"both\", bottom=False, labelbottom=False)\r\n",
							"plt.plot(\r\n",
							"    rdf[\"timestamp\"],\r\n",
							"    rdf[\"severity\"],\r\n",
							"    color=\"black\",\r\n",
							"    #line,\r\n",
							"    linewidth=2,\r\n",
							"    label=\"Severity score\",\r\n",
							")\r\n",
							"plt.plot(\r\n",
							"    rdf[\"timestamp\"],\r\n",
							"    [minSeverity] * len(rdf[\"severity\"]),\r\n",
							"    color=\"red\",\r\n",
							"    #line,\r\n",
							"    linewidth=1,\r\n",
							"    label=\"minSeverity\",\r\n",
							")\r\n",
							"plt.grid(axis=\"y\")\r\n",
							"plt.legend()\r\n",
							"plt.ylim([0, 1])\r\n",
							"plt.title(\"Severity of the detected anomalies\")\r\n",
							"plt.show()\r\n",
							"\r\n",
							"####### Contributors Figure #######\r\n",
							"plt.figure(figsize=(23, 1))\r\n",
							"plt.tick_params(axis=\"x\", which=\"both\", bottom=False, labelbottom=False)\r\n",
							"plt.bar(\r\n",
							"    rdf[\"timestamp\"], rdf[\"series_0\"], width=2, color=\"tab:orange\", label=\"sensor_1\"\r\n",
							")\r\n",
							"plt.bar(\r\n",
							"    rdf[\"timestamp\"],\r\n",
							"    rdf[\"series_1\"],\r\n",
							"    width=2,\r\n",
							"    color=\"tab:green\",\r\n",
							"    label=\"sensor_2\",\r\n",
							"    bottom=rdf[\"series_0\"],\r\n",
							")\r\n",
							"plt.bar(\r\n",
							"    rdf[\"timestamp\"],\r\n",
							"    rdf[\"series_2\"],\r\n",
							"    width=2,\r\n",
							"    color=\"tab:blue\",\r\n",
							"    label=\"sensor_3\",\r\n",
							"    bottom=rdf[\"series_0\"] + rdf[\"series_1\"],\r\n",
							")\r\n",
							"plt.grid(axis=\"y\")\r\n",
							"plt.legend()\r\n",
							"plt.ylim([0, 1])\r\n",
							"plt.title(\"The contribution of each sensor to the detected anomaly\")\r\n",
							"plt.show()"
						],
						"outputs": [],
						"execution_count": 55
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"simpleMultiAnomalyEstimator.cleanUpIntermediateData()\r\n",
							"model.cleanUpIntermediateData()"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/nyxtaxidatasave')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "74a8231a-0d36-4dff-8fb3-f4b882fb4a87"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import matplotlib.pyplot as plt\r\n",
							"\r\n",
							"from pyspark.sql.functions import unix_timestamp\r\n",
							"\r\n",
							"from pyspark.sql import SparkSession\r\n",
							"from pyspark.sql.types import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"from pyspark.ml import Pipeline\r\n",
							"from pyspark.ml import PipelineModel\r\n",
							"from pyspark.ml.feature import RFormula\r\n",
							"from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\r\n",
							"from pyspark.ml.classification import LogisticRegression\r\n",
							"from pyspark.mllib.evaluation import BinaryClassificationMetrics\r\n",
							"from pyspark.ml.evaluation import BinaryClassificationEvaluator"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Import NYC yellow cab data from Azure Open Datasets\r\n",
							"from azureml.opendatasets import NycTlcYellow\r\n",
							"\r\n",
							"from datetime import datetime\r\n",
							"from dateutil import parser\r\n",
							"\r\n",
							"end_date = parser.parse('2018-12-31 00:00:00')\r\n",
							"start_date = parser.parse('2018-01-01 00:00:00')\r\n",
							"\r\n",
							"nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\r\n",
							"nyc_tlc_df = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"nyc_tlc_df.count()"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"nyc_tlc_df.repartition(5).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/yellowtaxi/')"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from azureml.opendatasets import NycTlcGreen\r\n",
							"\r\n",
							"from datetime import datetime\r\n",
							"from dateutil import parser\r\n",
							"end_date = parser.parse('2018-12-31')\r\n",
							"start_date = parser.parse('2018-01-01')\r\n",
							"\r\n",
							"nyc_tlc = NycTlcGreen(start_date=start_date, end_date=end_date)\r\n",
							"nyc_tlc_dfg = nyc_tlc.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"nyc_tlc_dfg.count()"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"nyc_tlc_dfg.repartition(1).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/greentaxi/')"
						],
						"outputs": [],
						"execution_count": 29
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/searchml')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "cd42a89f-e98c-45e7-bbd8-415032a09b49"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"%%configure -f\r\n",
							"{\r\n",
							"  \"name\": \"synapseml\",\r\n",
							"  \"conf\": {\r\n",
							"      \"spark.jars.packages\": \"com.microsoft.azure:synapseml_2.12:0.10.0\",\r\n",
							"      \"spark.jars.repositories\": \"https://mmlspark.azureedge.net/maven\",\r\n",
							"      \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind\",\r\n",
							"      \"spark.yarn.user.classpath.first\": \"true\"\r\n",
							"  }\r\n",
							"}"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#cogsvc = token_library.GetSecret(\"mlopskeyv1\", \"cogsvc\", \"mlopskey1\")\r\n",
							"#cogsvc = TokenLibrary.getSecretWithLS(\"mlopskeyv1\", \"cogsvc\")\r\n",
							"# getSecret(akvName: String, secret: String, linkedService: String)\r\n",
							"# cogsvc = TokenLibrary.getSecret(\"mlopskeyv1\", \"cogsvc\", \"mlopskey1\")\r\n",
							"# https://learn.microsoft.com/en-us/azure/search/search-synapseml-cognitive-services\r\n",
							"cogsvc= mssparkutils.credentials.getSecret(\"mlopskeyv1\", \"cogsvc\")\r\n",
							"cogsearchname= mssparkutils.credentials.getSecret(\"mlopskeyv1\", \"cogsearchname\")\r\n",
							"cogsearchkey= mssparkutils.credentials.getSecret(\"mlopskeyv1\", \"cogsearchkey\")\r\n",
							"#print(cogsvc)"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import os\r\n",
							"from pyspark.sql.functions import udf, trim, split, explode, col, monotonically_increasing_id, lit\r\n",
							"from pyspark.sql.types import StringType\r\n",
							"from synapse.ml.core.spark import FluentAPI\r\n",
							"\r\n",
							"cognitive_services_key = cogsvc\r\n",
							"cognitive_services_region = \"eastus2\"\r\n",
							"\r\n",
							"search_service = cogsearchname\r\n",
							"search_key = cogsearchkey\r\n",
							"search_index = \"synapseindex\""
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"def blob_to_url(blob):\r\n",
							"    [prefix, postfix] = blob.split(\"@\")\r\n",
							"    container = prefix.split(\"/\")[-1]\r\n",
							"    split_postfix = postfix.split(\"/\")\r\n",
							"    account = split_postfix[0]\r\n",
							"    filepath = \"/\".join(split_postfix[1:])\r\n",
							"    return \"https://{}/{}/{}\".format(account, container, filepath)\r\n",
							"\r\n",
							"\r\n",
							"df2 = (spark.read.format(\"binaryFile\")\r\n",
							"    .load(\"wasbs://ignite2021@mmlsparkdemo.blob.core.windows.net/form_subset/*\")\r\n",
							"    .select(\"path\")\r\n",
							"    .limit(10)\r\n",
							"    .select(udf(blob_to_url, StringType())(\"path\").alias(\"url\"))\r\n",
							"    .cache())\r\n",
							"    \r\n",
							"display(df2)"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from synapse.ml.cognitive import AnalyzeInvoices\r\n",
							"\r\n",
							"analyzed_df = (AnalyzeInvoices()\r\n",
							"    .setSubscriptionKey(cognitive_services_key)\r\n",
							"    .setLocation(cognitive_services_region)\r\n",
							"    .setImageUrlCol(\"url\")\r\n",
							"    .setOutputCol(\"invoices\")\r\n",
							"    .setErrorCol(\"errors\")\r\n",
							"    .setConcurrency(5)\r\n",
							"    .transform(df2)\r\n",
							"    .cache())\r\n",
							"\r\n",
							"display(analyzed_df)"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from synapse.ml.cognitive import FormOntologyLearner\r\n",
							"\r\n",
							"itemized_df = (FormOntologyLearner()\r\n",
							"    .setInputCol(\"invoices\")\r\n",
							"    .setOutputCol(\"extracted\")\r\n",
							"    .fit(analyzed_df)\r\n",
							"    .transform(analyzed_df)\r\n",
							"    .select(\"url\", \"extracted.*\").select(\"*\", explode(col(\"Items\")).alias(\"Item\"))\r\n",
							"    .drop(\"Items\").select(\"Item.*\", \"*\").drop(\"Item\"))\r\n",
							"\r\n",
							"display(itemized_df)"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"from synapse.ml.cognitive import Translate\r\n",
							"\r\n",
							"translated_df = (Translate()\r\n",
							"    .setSubscriptionKey(cognitive_services_key)\r\n",
							"    .setLocation(cognitive_services_region)\r\n",
							"    .setTextCol(\"Description\")\r\n",
							"    .setErrorCol(\"TranslationError\")\r\n",
							"    .setOutputCol(\"output\")\r\n",
							"    .setToLanguage([\"zh-Hans\", \"fr\", \"ru\", \"cy\"])\r\n",
							"    .setConcurrency(5)\r\n",
							"    .transform(itemized_df)\r\n",
							"    .withColumn(\"Translations\", col(\"output.translations\")[0])\r\n",
							"    .drop(\"output\", \"TranslationError\")\r\n",
							"    .cache())\r\n",
							"\r\n",
							"display(translated_df)"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from synapse.ml.cognitive import *\r\n",
							"\r\n",
							"(translated_df.withColumn(\"DocID\", monotonically_increasing_id().cast(\"string\"))\r\n",
							"    .withColumn(\"SearchAction\", lit(\"upload\"))\r\n",
							"    .writeToAzureSearch(\r\n",
							"        subscriptionKey=search_key,\r\n",
							"        actionCol=\"SearchAction\",\r\n",
							"        serviceName=search_service,\r\n",
							"        indexName=search_index,\r\n",
							"        keyCol=\"DocID\",\r\n",
							"    ))"
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import requests\r\n",
							"\r\n",
							"url = \"https://{}.search.windows.net/indexes/{}/docs/search?api-version=2020-06-30\".format(search_service, search_index)\r\n",
							"requests.post(url, json={\"search\": \"door\", \"count\": \"true\", \"select\": \"Description, Translations\"}, headers={\"api-key\": search_key}).json()"
						],
						"outputs": [],
						"execution_count": 29
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchaggreoutputval')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 3,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "3",
						"spark.dynamicAllocation.maxExecutors": "3",
						"spark.autotune.trackingId": "8658c483-1fd1-436d-9937-86df1c76ed33"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://root@synpasedlstore.dfs.core.windows.net/tpchoutput/dailyordersbycustomers/year=*/month=*/*.snappy.parquet', format='parquet')\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.count()"
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchdataengg')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "112g",
					"driverCores": 16,
					"executorMemory": "112g",
					"executorCores": 16,
					"numExecutors": 5,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "5",
						"spark.dynamicAllocation.maxExecutors": "5",
						"spark.autotune.trackingId": "0917d947-d37c-47df-bbfd-4796b0efea89"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"dfcustomer = spark.read.load('abfss://root@synpasedlstore.dfs.core.windows.net/tpch/CUSTOMER/*.parquet', format='parquet')\r\n",
							"display(dfcustomer.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"dforders = spark.read.load('abfss://root@synpasedlstore.dfs.core.windows.net/tpch/ORDERS/*.parquet', format='parquet')\r\n",
							"display(dforders.limit(10))"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"dflineitems = spark.read.load('abfss://root@synpasedlstore.dfs.core.windows.net/tpch/LINEITEM/*.parquet', format='parquet')\r\n",
							"display(dflineitems.limit(10))"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dforders.join(dflineitems,dforders[\"O_ORDERKEY\"] == dflineitems[\"L_ORDERKEY\"]).show()"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchfewfiles')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 3,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "3",
						"spark.dynamicAllocation.maxExecutors": "3",
						"spark.autotune.trackingId": "f65760c3-22e1-4a2f-8946-da841809b254"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load([\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM/part-00000-66924ccf-4407-468d-925e-287543687446-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM/part-00001-66924ccf-4407-468d-925e-287543687446-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM/part-00002-66924ccf-4407-468d-925e-287543687446-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM/part-00003-66924ccf-4407-468d-925e-287543687446-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM/part-00004-66924ccf-4407-468d-925e-287543687446-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM/part-00005-66924ccf-4407-468d-925e-287543687446-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM/part-00006-66924ccf-4407-468d-925e-287543687446-c000.snappy.parquet'\r\n",
							"    ], format='parquet')\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.repartition(7).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/tpch2/LINEITEM')"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load([\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS/part-00000-f9e6f6da-70fe-4141-8e95-f2487d485d86-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS/part-00001-f9e6f6da-70fe-4141-8e95-f2487d485d86-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS/part-00002-f9e6f6da-70fe-4141-8e95-f2487d485d86-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS/part-00003-f9e6f6da-70fe-4141-8e95-f2487d485d86-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS/part-00004-f9e6f6da-70fe-4141-8e95-f2487d485d86-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS/part-00005-f9e6f6da-70fe-4141-8e95-f2487d485d86-c000.snappy.parquet',\r\n",
							"    'abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS/part-00006-f9e6f6da-70fe-4141-8e95-f2487d485d86-c000.snappy.parquet'\r\n",
							"    ], format='parquet')\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.repartition(7).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/tpch2/ORDERS')"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchlineitemengg')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "cf22ceeb-a6c0-4ca6-808f-0247d8a4d11e"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%%configure -f\r\n",
							"{\r\n",
							"    \"driverMemory\": \"28g\",\r\n",
							"    \"driverCores\": 4,\r\n",
							"    \"executorMemory\": \"32g\",\r\n",
							"    \"executorCores\": 4,\r\n",
							"    \"numExecutors\" : 5,\r\n",
							"    \"spark.kryoserializer.buffer.max\" : 78244772\r\n",
							"}"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://root@synpasedlstore.dfs.core.windows.net/tpch/LINEITEM/*.parquet', format='parquet')\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.count()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.take(10)"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyspark.sql.functions as func\r\n",
							"\r\n",
							"#df1 = df.select(func.to_date(df.L_SHIPDATE).alias(\"time\"))\r\n",
							"sf = df.filter(df['L_SHIPDATE'] > '1992-05-05').filter(df['L_SHIPDATE'] < '1992-05-30')"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sf.count()"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sf.repartition(15).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM')"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dfread = spark.read.parquet('abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/LINEITEM')"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"display(dfread)"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://root@synpasedlstore.dfs.core.windows.net/tpch/ORDERS/*.parquet', format='parquet')\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pyspark.sql.functions as func\r\n",
							"\r\n",
							"#df1 = df.select(func.to_date(df.L_SHIPDATE).alias(\"time\"))\r\n",
							"sf = df.filter(df['O_ORDERDATE'] > '1992-05-05').filter(df['O_ORDERDATE'] < '1992-05-30')"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sf.repartition(15).write.mode(\"overwrite\").parquet('abfss://root@synpasedlstore.dfs.core.windows.net/tpch1/ORDERS')"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/tpchoutputspark')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "spark32",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "224g",
					"driverCores": 32,
					"executorMemory": "224g",
					"executorCores": 32,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b744df1d-c2be-4f24-b3b6-5c87bc6882b9"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourceGroups/mlopsdeveast/providers/Microsoft.Synapse/workspaces/synpasedl/bigDataPools/spark32",
						"name": "spark32",
						"type": "Spark",
						"endpoint": "https://synpasedl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark32",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.2",
						"nodeCount": 10,
						"cores": 32,
						"memory": 224
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://root@synpasedlstore.dfs.core.windows.net/tpchoutput/dailyordersbycustomers/year=1994/month=2/part-00002-99668778-ef7d-403a-b95b-88dce6cb6e2d.c000.snappy.parquet', format='parquet')\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.columns"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark32')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 20,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "XLarge",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.2",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/spark31')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Large",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		}
	]
}